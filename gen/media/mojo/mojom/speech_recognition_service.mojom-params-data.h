// media/mojo/mojom/speech_recognition_service.mojom-params-data.h is auto generated by mojom_bindings_generator.py, do not edit

// Copyright 2019 The Chromium Authors
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#ifndef MEDIA_MOJO_MOJOM_SPEECH_RECOGNITION_SERVICE_MOJOM_PARAMS_DATA_H_
#define MEDIA_MOJO_MOJOM_SPEECH_RECOGNITION_SERVICE_MOJOM_PARAMS_DATA_H_

#include "mojo/public/cpp/bindings/lib/bindings_internal.h"
#include "mojo/public/cpp/bindings/lib/buffer.h"

#if defined(__clang__)
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wunused-private-field"
#endif

namespace mojo::internal {
class ValidationContext;
}

namespace media::mojom {
namespace internal {
class AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_Params_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;
    mojo::internal::Handle_Data fetcher_receiver;
    mojo::internal::Interface_Data client;
    uint8_t pad1_[4];
    mojo::internal::Pointer<::media::mojom::internal::SpeechRecognitionOptions_Data> options;

private:
    friend class mojo::internal::MessageFragment<AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_Params_Data>;

    AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_Params_Data();
    ~AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_Params_Data() = delete;
};
static_assert(sizeof(AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_Params_Data) == 32,
    "Bad sizeof(AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_Params_Data)");
class AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParams_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;
    uint8_t is_multichannel_supported : 1;
    uint8_t padfinal_[7];

private:
    friend class mojo::internal::MessageFragment<AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParams_Data>;

    AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParams_Data();
    ~AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParams_Data() = delete;
};
static_assert(sizeof(AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParams_Data) == 16,
    "Bad sizeof(AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParams_Data)");
class SpeechRecognitionService_BindSpeechRecognitionContext_Params_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;
    mojo::internal::Handle_Data context;
    uint8_t padfinal_[4];

private:
    friend class mojo::internal::MessageFragment<SpeechRecognitionService_BindSpeechRecognitionContext_Params_Data>;

    SpeechRecognitionService_BindSpeechRecognitionContext_Params_Data();
    ~SpeechRecognitionService_BindSpeechRecognitionContext_Params_Data() = delete;
};
static_assert(sizeof(SpeechRecognitionService_BindSpeechRecognitionContext_Params_Data) == 16,
    "Bad sizeof(SpeechRecognitionService_BindSpeechRecognitionContext_Params_Data)");
class SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_Params_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;
    mojo::internal::Handle_Data context;
    uint8_t padfinal_[4];

private:
    friend class mojo::internal::MessageFragment<SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_Params_Data>;

    SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_Params_Data();
    ~SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_Params_Data() = delete;
};
static_assert(sizeof(SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_Params_Data) == 16,
    "Bad sizeof(SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_Params_Data)");
class SpeechRecognitionService_SetSodaPaths_Params_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;
    mojo::internal::Pointer<::mojo_base::mojom::internal::FilePath_Data> binary_path;
    mojo::internal::Pointer<
        mojo::internal::Map_Data<mojo::internal::Pointer<mojo::internal::String_Data>, mojo::internal::Pointer<::mojo_base::mojom::internal::FilePath_Data>>>
        config_paths;
    mojo::internal::Pointer<mojo::internal::String_Data> primary_language_name;

private:
    friend class mojo::internal::MessageFragment<SpeechRecognitionService_SetSodaPaths_Params_Data>;

    SpeechRecognitionService_SetSodaPaths_Params_Data();
    ~SpeechRecognitionService_SetSodaPaths_Params_Data() = delete;
};
static_assert(sizeof(SpeechRecognitionService_SetSodaPaths_Params_Data) == 32, "Bad sizeof(SpeechRecognitionService_SetSodaPaths_Params_Data)");
class SpeechRecognitionService_SetSodaParams_Params_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;
    uint8_t mask_offensive_words : 1;
    uint8_t padfinal_[7];

private:
    friend class mojo::internal::MessageFragment<SpeechRecognitionService_SetSodaParams_Params_Data>;

    SpeechRecognitionService_SetSodaParams_Params_Data();
    ~SpeechRecognitionService_SetSodaParams_Params_Data() = delete;
};
static_assert(sizeof(SpeechRecognitionService_SetSodaParams_Params_Data) == 16, "Bad sizeof(SpeechRecognitionService_SetSodaParams_Params_Data)");
class SpeechRecognitionService_SetSodaConfigPaths_Params_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;
    mojo::internal::Pointer<
        mojo::internal::Map_Data<mojo::internal::Pointer<mojo::internal::String_Data>, mojo::internal::Pointer<::mojo_base::mojom::internal::FilePath_Data>>>
        config_paths;

private:
    friend class mojo::internal::MessageFragment<SpeechRecognitionService_SetSodaConfigPaths_Params_Data>;

    SpeechRecognitionService_SetSodaConfigPaths_Params_Data();
    ~SpeechRecognitionService_SetSodaConfigPaths_Params_Data() = delete;
};
static_assert(sizeof(SpeechRecognitionService_SetSodaConfigPaths_Params_Data) == 16, "Bad sizeof(SpeechRecognitionService_SetSodaConfigPaths_Params_Data)");
class AudioSourceFetcher_Start_Params_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;
    mojo::internal::Interface_Data factory;
    mojo::internal::Pointer<mojo::internal::String_Data> device_id;
    mojo::internal::Pointer<::media::mojom::internal::AudioParameters_Data> audio_parameters;

private:
    friend class mojo::internal::MessageFragment<AudioSourceFetcher_Start_Params_Data>;

    AudioSourceFetcher_Start_Params_Data();
    ~AudioSourceFetcher_Start_Params_Data() = delete;
};
static_assert(sizeof(AudioSourceFetcher_Start_Params_Data) == 32, "Bad sizeof(AudioSourceFetcher_Start_Params_Data)");
class AudioSourceFetcher_Stop_Params_Data {
public:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);

    mojo::internal::StructHeader header_;

private:
    friend class mojo::internal::MessageFragment<AudioSourceFetcher_Stop_Params_Data>;

    AudioSourceFetcher_Stop_Params_Data();
    ~AudioSourceFetcher_Stop_Params_Data() = delete;
};
static_assert(sizeof(AudioSourceFetcher_Stop_Params_Data) == 8, "Bad sizeof(AudioSourceFetcher_Stop_Params_Data)");

} // namespace internal

class AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ParamsDataView {
public:
    AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ParamsDataView() = default;

    AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ParamsDataView(
        internal::AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_Params_Data* data, mojo::Message* message)
        : data_(data)
        , message_(message)
    {
    }

    bool is_null() const
    {
        return !data_;
    }
    template <typename UserType> UserType TakeFetcherReceiver()
    {
        UserType result;
        bool ret = mojo::internal::Deserialize<mojo::InterfaceRequestDataView<::media::mojom::AudioSourceFetcherInterfaceBase>>(
            &data_->fetcher_receiver, &result, message_);
        DCHECK(ret);
        return result;
    }
    template <typename UserType> UserType TakeClient()
    {
        UserType result;
        bool ret = mojo::internal::Deserialize<mojo::InterfacePtrDataView<::media::mojom::SpeechRecognitionRecognizerClientInterfaceBase>>(
            &data_->client, &result, message_);
        DCHECK(ret);
        return result;
    }
    inline void GetOptionsDataView(::media::mojom::SpeechRecognitionOptionsDataView* output);

    template <typename UserType> [[nodiscard]] bool ReadOptions(UserType* output)
    {

        auto* pointer = data_->options.Get();
        return mojo::internal::Deserialize<::media::mojom::SpeechRecognitionOptionsDataView>(pointer, output, message_);
    }

private:
    internal::AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_Params_Data* data_ = nullptr;
    mojo::Message* message_ = nullptr;
};

class AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParamsDataView {
public:
    AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParamsDataView() = default;

    AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParamsDataView(
        internal::AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParams_Data* data, mojo::Message* message)
        : data_(data)
    {
    }

    bool is_null() const
    {
        return !data_;
    }
    bool is_multichannel_supported() const
    {
        return data_->is_multichannel_supported;
    }

private:
    internal::AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ResponseParams_Data* data_ = nullptr;
};

class SpeechRecognitionService_BindSpeechRecognitionContext_ParamsDataView {
public:
    SpeechRecognitionService_BindSpeechRecognitionContext_ParamsDataView() = default;

    SpeechRecognitionService_BindSpeechRecognitionContext_ParamsDataView(
        internal::SpeechRecognitionService_BindSpeechRecognitionContext_Params_Data* data, mojo::Message* message)
        : data_(data)
        , message_(message)
    {
    }

    bool is_null() const
    {
        return !data_;
    }
    template <typename UserType> UserType TakeContext()
    {
        UserType result;
        bool ret = mojo::internal::Deserialize<mojo::InterfaceRequestDataView<::media::mojom::SpeechRecognitionContextInterfaceBase>>(
            &data_->context, &result, message_);
        DCHECK(ret);
        return result;
    }

private:
    internal::SpeechRecognitionService_BindSpeechRecognitionContext_Params_Data* data_ = nullptr;
    mojo::Message* message_ = nullptr;
};

class SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_ParamsDataView {
public:
    SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_ParamsDataView() = default;

    SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_ParamsDataView(
        internal::SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_Params_Data* data, mojo::Message* message)
        : data_(data)
        , message_(message)
    {
    }

    bool is_null() const
    {
        return !data_;
    }
    template <typename UserType> UserType TakeContext()
    {
        UserType result;
        bool ret = mojo::internal::Deserialize<mojo::InterfaceRequestDataView<::media::mojom::AudioSourceSpeechRecognitionContextInterfaceBase>>(
            &data_->context, &result, message_);
        DCHECK(ret);
        return result;
    }

private:
    internal::SpeechRecognitionService_BindAudioSourceSpeechRecognitionContext_Params_Data* data_ = nullptr;
    mojo::Message* message_ = nullptr;
};

class SpeechRecognitionService_SetSodaPaths_ParamsDataView {
public:
    SpeechRecognitionService_SetSodaPaths_ParamsDataView() = default;

    SpeechRecognitionService_SetSodaPaths_ParamsDataView(internal::SpeechRecognitionService_SetSodaPaths_Params_Data* data, mojo::Message* message)
        : data_(data)
        , message_(message)
    {
    }

    bool is_null() const
    {
        return !data_;
    }
    inline void GetBinaryPathDataView(::mojo_base::mojom::FilePathDataView* output);

    template <typename UserType> [[nodiscard]] bool ReadBinaryPath(UserType* output)
    {

        auto* pointer = data_->binary_path.Get();
        return mojo::internal::Deserialize<::mojo_base::mojom::FilePathDataView>(pointer, output, message_);
    }
    inline void GetConfigPathsDataView(mojo::MapDataView<mojo::StringDataView, ::mojo_base::mojom::FilePathDataView>* output);

    template <typename UserType> [[nodiscard]] bool ReadConfigPaths(UserType* output)
    {

        auto* pointer = data_->config_paths.Get();
        return mojo::internal::Deserialize<mojo::MapDataView<mojo::StringDataView, ::mojo_base::mojom::FilePathDataView>>(pointer, output, message_);
    }
    inline void GetPrimaryLanguageNameDataView(mojo::StringDataView* output);

    template <typename UserType> [[nodiscard]] bool ReadPrimaryLanguageName(UserType* output)
    {

        auto* pointer = data_->primary_language_name.Get();
        return mojo::internal::Deserialize<mojo::StringDataView>(pointer, output, message_);
    }

private:
    internal::SpeechRecognitionService_SetSodaPaths_Params_Data* data_ = nullptr;
    mojo::Message* message_ = nullptr;
};

class SpeechRecognitionService_SetSodaParams_ParamsDataView {
public:
    SpeechRecognitionService_SetSodaParams_ParamsDataView() = default;

    SpeechRecognitionService_SetSodaParams_ParamsDataView(internal::SpeechRecognitionService_SetSodaParams_Params_Data* data, mojo::Message* message)
        : data_(data)
    {
    }

    bool is_null() const
    {
        return !data_;
    }
    bool mask_offensive_words() const
    {
        return data_->mask_offensive_words;
    }

private:
    internal::SpeechRecognitionService_SetSodaParams_Params_Data* data_ = nullptr;
};

class SpeechRecognitionService_SetSodaConfigPaths_ParamsDataView {
public:
    SpeechRecognitionService_SetSodaConfigPaths_ParamsDataView() = default;

    SpeechRecognitionService_SetSodaConfigPaths_ParamsDataView(internal::SpeechRecognitionService_SetSodaConfigPaths_Params_Data* data, mojo::Message* message)
        : data_(data)
        , message_(message)
    {
    }

    bool is_null() const
    {
        return !data_;
    }
    inline void GetConfigPathsDataView(mojo::MapDataView<mojo::StringDataView, ::mojo_base::mojom::FilePathDataView>* output);

    template <typename UserType> [[nodiscard]] bool ReadConfigPaths(UserType* output)
    {

        auto* pointer = data_->config_paths.Get();
        return mojo::internal::Deserialize<mojo::MapDataView<mojo::StringDataView, ::mojo_base::mojom::FilePathDataView>>(pointer, output, message_);
    }

private:
    internal::SpeechRecognitionService_SetSodaConfigPaths_Params_Data* data_ = nullptr;
    mojo::Message* message_ = nullptr;
};

class AudioSourceFetcher_Start_ParamsDataView {
public:
    AudioSourceFetcher_Start_ParamsDataView() = default;

    AudioSourceFetcher_Start_ParamsDataView(internal::AudioSourceFetcher_Start_Params_Data* data, mojo::Message* message)
        : data_(data)
        , message_(message)
    {
    }

    bool is_null() const
    {
        return !data_;
    }
    template <typename UserType> UserType TakeFactory()
    {
        UserType result;
        bool ret = mojo::internal::Deserialize<mojo::InterfacePtrDataView<::media::mojom::AudioStreamFactoryInterfaceBase>>(&data_->factory, &result, message_);
        DCHECK(ret);
        return result;
    }
    inline void GetDeviceIdDataView(mojo::StringDataView* output);

    template <typename UserType> [[nodiscard]] bool ReadDeviceId(UserType* output)
    {

        auto* pointer = data_->device_id.Get();
        return mojo::internal::Deserialize<mojo::StringDataView>(pointer, output, message_);
    }
    inline void GetAudioParametersDataView(::media::mojom::AudioParametersDataView* output);

    template <typename UserType> [[nodiscard]] bool ReadAudioParameters(UserType* output)
    {

        auto* pointer = data_->audio_parameters.Get();
        return mojo::internal::Deserialize<::media::mojom::AudioParametersDataView>(pointer, output, message_);
    }

private:
    internal::AudioSourceFetcher_Start_Params_Data* data_ = nullptr;
    mojo::Message* message_ = nullptr;
};

class AudioSourceFetcher_Stop_ParamsDataView {
public:
    AudioSourceFetcher_Stop_ParamsDataView() = default;

    AudioSourceFetcher_Stop_ParamsDataView(internal::AudioSourceFetcher_Stop_Params_Data* data, mojo::Message* message)
        : data_(data)
    {
    }

    bool is_null() const
    {
        return !data_;
    }

private:
    internal::AudioSourceFetcher_Stop_Params_Data* data_ = nullptr;
};

inline void AudioSourceSpeechRecognitionContext_BindAudioSourceFetcher_ParamsDataView::GetOptionsDataView(
    ::media::mojom::SpeechRecognitionOptionsDataView* output)
{
    auto pointer = data_->options.Get();
    *output = ::media::mojom::SpeechRecognitionOptionsDataView(pointer, message_);
}

inline void SpeechRecognitionService_SetSodaPaths_ParamsDataView::GetBinaryPathDataView(::mojo_base::mojom::FilePathDataView* output)
{
    auto pointer = data_->binary_path.Get();
    *output = ::mojo_base::mojom::FilePathDataView(pointer, message_);
}
inline void SpeechRecognitionService_SetSodaPaths_ParamsDataView::GetConfigPathsDataView(
    mojo::MapDataView<mojo::StringDataView, ::mojo_base::mojom::FilePathDataView>* output)
{
    auto pointer = data_->config_paths.Get();
    *output = mojo::MapDataView<mojo::StringDataView, ::mojo_base::mojom::FilePathDataView>(pointer, message_);
}
inline void SpeechRecognitionService_SetSodaPaths_ParamsDataView::GetPrimaryLanguageNameDataView(mojo::StringDataView* output)
{
    auto pointer = data_->primary_language_name.Get();
    *output = mojo::StringDataView(pointer, message_);
}

inline void SpeechRecognitionService_SetSodaConfigPaths_ParamsDataView::GetConfigPathsDataView(
    mojo::MapDataView<mojo::StringDataView, ::mojo_base::mojom::FilePathDataView>* output)
{
    auto pointer = data_->config_paths.Get();
    *output = mojo::MapDataView<mojo::StringDataView, ::mojo_base::mojom::FilePathDataView>(pointer, message_);
}

inline void AudioSourceFetcher_Start_ParamsDataView::GetDeviceIdDataView(mojo::StringDataView* output)
{
    auto pointer = data_->device_id.Get();
    *output = mojo::StringDataView(pointer, message_);
}
inline void AudioSourceFetcher_Start_ParamsDataView::GetAudioParametersDataView(::media::mojom::AudioParametersDataView* output)
{
    auto pointer = data_->audio_parameters.Get();
    *output = ::media::mojom::AudioParametersDataView(pointer, message_);
}

} // media::mojom

#if defined(__clang__)
#pragma clang diagnostic pop
#endif

#endif // MEDIA_MOJO_MOJOM_SPEECH_RECOGNITION_SERVICE_MOJOM_PARAMS_DATA_H_
