// media/mojo/mojom/speech_recognizer.mojom-blink.h is auto generated by mojom_bindings_generator.py, do not edit

// Copyright 2013 The Chromium Authors
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#ifndef MEDIA_MOJO_MOJOM_SPEECH_RECOGNIZER_MOJOM_BLINK_H_
#define MEDIA_MOJO_MOJOM_SPEECH_RECOGNIZER_MOJOM_BLINK_H_

#include <stdint.h>

#include <limits>
#include <optional>
#include <type_traits>
#include <utility>

#include "base/types/cxx23_to_underlying.h"
#include "mojo/public/cpp/bindings/clone_traits.h"
#include "mojo/public/cpp/bindings/equals_traits.h"
#include "mojo/public/cpp/bindings/lib/serialization.h"
#include "mojo/public/cpp/bindings/struct_ptr.h"
#include "mojo/public/cpp/bindings/struct_traits.h"
#include "mojo/public/cpp/bindings/union_traits.h"

#include "third_party/perfetto/include/perfetto/tracing/traced_value_forward.h"

#include "media/mojo/mojom/speech_recognizer.mojom-features.h" // IWYU pragma: export
#include "media/mojo/mojom/speech_recognizer.mojom-shared.h" // IWYU pragma: export
#include "media/mojo/mojom/speech_recognizer.mojom-blink-forward.h" // IWYU pragma: export
#include "media/mojo/mojom/speech_recognition_audio_forwarder.mojom-blink-forward.h"
#include "media/mojo/mojom/speech_recognition_error.mojom-blink-forward.h"
#include "media/mojo/mojom/speech_recognition_grammar.mojom-blink.h"
#include "media/mojo/mojom/speech_recognition_result.mojom-blink-forward.h"

#include "mojo/public/cpp/bindings/lib/wtf_clone_equals_util.h"
#include "mojo/public/cpp/bindings/lib/wtf_hash_util.h"
#include "third_party/blink/renderer/platform/wtf/hash_functions.h"
#include "third_party/blink/renderer/platform/wtf/text/wtf_string.h"

#include "mojo/public/cpp/bindings/lib/control_message_handler.h"
#include "mojo/public/cpp/bindings/lib/message_size_estimator.h"
#include "mojo/public/cpp/bindings/raw_ptr_impl_ref_traits.h"

#include "third_party/blink/public/platform/web_common.h"
#if !BLINK_MOJO_IMPL && !INSIDE_BLINK
#error "File must only be imported inside blink"
#endif

namespace media::mojom::blink {

class SpeechRecognizerProxy;

template <typename ImplRefTraits> class SpeechRecognizerStub;

class SpeechRecognizerRequestValidator;

class BLINK_PLATFORM_EXPORT SpeechRecognizer : public SpeechRecognizerInterfaceBase {
public:
    using IPCStableHashFunction = uint32_t (*)();

    static const char Name_[];
    static IPCStableHashFunction MessageToMethodInfo_(mojo::Message& message);
    static const char* MessageToMethodName_(mojo::Message& message);
    static constexpr uint32_t Version_ = 0;
    static constexpr bool PassesAssociatedKinds_ = false;
    static constexpr bool HasUninterruptableMethods_ = false;

    using Base_ = SpeechRecognizerInterfaceBase;
    using Proxy_ = SpeechRecognizerProxy;

    template <typename ImplRefTraits> using Stub_ = SpeechRecognizerStub<ImplRefTraits>;

    using RequestValidator_ = SpeechRecognizerRequestValidator;
    using ResponseValidator_ = mojo::PassThroughFilter;
    enum MethodMinVersions : uint32_t {
        kStartMinVersion = 0,
    };

// crbug.com/1340245 - this causes binary size bloat on Fuchsia, and we're OK
// with not having this data in traces there.
#if !BUILDFLAG(IS_FUCHSIA)
    struct Start_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
#endif // !BUILDFLAG(IS_FUCHSIA)
    virtual ~SpeechRecognizer() = default;

    virtual void Start(StartSpeechRecognitionRequestParamsPtr params) = 0;
};

class OnDeviceSpeechRecognitionProxy;

template <typename ImplRefTraits> class OnDeviceSpeechRecognitionStub;

class OnDeviceSpeechRecognitionRequestValidator;
class OnDeviceSpeechRecognitionResponseValidator;

class BLINK_PLATFORM_EXPORT OnDeviceSpeechRecognition : public OnDeviceSpeechRecognitionInterfaceBase {
public:
    using IPCStableHashFunction = uint32_t (*)();

    static const char Name_[];
    static IPCStableHashFunction MessageToMethodInfo_(mojo::Message& message);
    static const char* MessageToMethodName_(mojo::Message& message);
    static constexpr uint32_t Version_ = 0;
    static constexpr bool PassesAssociatedKinds_ = false;
    static constexpr bool HasUninterruptableMethods_ = false;

    using Base_ = OnDeviceSpeechRecognitionInterfaceBase;
    using Proxy_ = OnDeviceSpeechRecognitionProxy;

    template <typename ImplRefTraits> using Stub_ = OnDeviceSpeechRecognitionStub<ImplRefTraits>;

    using RequestValidator_ = OnDeviceSpeechRecognitionRequestValidator;
    using ResponseValidator_ = OnDeviceSpeechRecognitionResponseValidator;
    enum MethodMinVersions : uint32_t {
        kOnDeviceWebSpeechAvailableMinVersion = 0,
        kInstallOnDeviceSpeechRecognitionMinVersion = 0,
    };

// crbug.com/1340245 - this causes binary size bloat on Fuchsia, and we're OK
// with not having this data in traces there.
#if !BUILDFLAG(IS_FUCHSIA)
    struct OnDeviceWebSpeechAvailable_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct InstallOnDeviceSpeechRecognition_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
#endif // !BUILDFLAG(IS_FUCHSIA)
    virtual ~OnDeviceSpeechRecognition() = default;

    using OnDeviceWebSpeechAvailableCallback = base::OnceCallback<void(bool)>;

    virtual void OnDeviceWebSpeechAvailable(const WTF::String& language, OnDeviceWebSpeechAvailableCallback callback) = 0;

    using InstallOnDeviceSpeechRecognitionCallback = base::OnceCallback<void(bool)>;

    virtual void InstallOnDeviceSpeechRecognition(const WTF::String& language, InstallOnDeviceSpeechRecognitionCallback callback) = 0;
};

class SpeechRecognitionSessionProxy;

template <typename ImplRefTraits> class SpeechRecognitionSessionStub;

class SpeechRecognitionSessionRequestValidator;

class BLINK_PLATFORM_EXPORT SpeechRecognitionSession : public SpeechRecognitionSessionInterfaceBase {
public:
    using IPCStableHashFunction = uint32_t (*)();

    static const char Name_[];
    static IPCStableHashFunction MessageToMethodInfo_(mojo::Message& message);
    static const char* MessageToMethodName_(mojo::Message& message);
    static constexpr uint32_t Version_ = 0;
    static constexpr bool PassesAssociatedKinds_ = false;
    static constexpr bool HasUninterruptableMethods_ = false;

    using Base_ = SpeechRecognitionSessionInterfaceBase;
    using Proxy_ = SpeechRecognitionSessionProxy;

    template <typename ImplRefTraits> using Stub_ = SpeechRecognitionSessionStub<ImplRefTraits>;

    using RequestValidator_ = SpeechRecognitionSessionRequestValidator;
    using ResponseValidator_ = mojo::PassThroughFilter;
    enum MethodMinVersions : uint32_t {
        kAbortMinVersion = 0,
        kStopCaptureMinVersion = 0,
    };

// crbug.com/1340245 - this causes binary size bloat on Fuchsia, and we're OK
// with not having this data in traces there.
#if !BUILDFLAG(IS_FUCHSIA)
    struct Abort_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct StopCapture_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
#endif // !BUILDFLAG(IS_FUCHSIA)
    virtual ~SpeechRecognitionSession() = default;

    virtual void Abort() = 0;

    virtual void StopCapture() = 0;
};

class SpeechRecognitionSessionClientProxy;

template <typename ImplRefTraits> class SpeechRecognitionSessionClientStub;

class SpeechRecognitionSessionClientRequestValidator;

class BLINK_PLATFORM_EXPORT SpeechRecognitionSessionClient : public SpeechRecognitionSessionClientInterfaceBase {
public:
    using IPCStableHashFunction = uint32_t (*)();

    static const char Name_[];
    static IPCStableHashFunction MessageToMethodInfo_(mojo::Message& message);
    static const char* MessageToMethodName_(mojo::Message& message);
    static constexpr uint32_t Version_ = 0;
    static constexpr bool PassesAssociatedKinds_ = false;
    static constexpr bool HasUninterruptableMethods_ = false;

    using Base_ = SpeechRecognitionSessionClientInterfaceBase;
    using Proxy_ = SpeechRecognitionSessionClientProxy;

    template <typename ImplRefTraits> using Stub_ = SpeechRecognitionSessionClientStub<ImplRefTraits>;

    using RequestValidator_ = SpeechRecognitionSessionClientRequestValidator;
    using ResponseValidator_ = mojo::PassThroughFilter;
    enum MethodMinVersions : uint32_t {
        kResultRetrievedMinVersion = 0,
        kErrorOccurredMinVersion = 0,
        kStartedMinVersion = 0,
        kAudioStartedMinVersion = 0,
        kSoundStartedMinVersion = 0,
        kSoundEndedMinVersion = 0,
        kAudioEndedMinVersion = 0,
        kEndedMinVersion = 0,
    };

// crbug.com/1340245 - this causes binary size bloat on Fuchsia, and we're OK
// with not having this data in traces there.
#if !BUILDFLAG(IS_FUCHSIA)
    struct ResultRetrieved_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct ErrorOccurred_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct Started_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct AudioStarted_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct SoundStarted_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct SoundEnded_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct AudioEnded_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
    struct Ended_Sym {
        NOINLINE static uint32_t IPCStableHash();
    };
#endif // !BUILDFLAG(IS_FUCHSIA)
    virtual ~SpeechRecognitionSessionClient() = default;

    virtual void ResultRetrieved(WTF::Vector<::media::mojom::blink::WebSpeechRecognitionResultPtr> results) = 0;

    virtual void ErrorOccurred(::media::mojom::blink::SpeechRecognitionErrorPtr error) = 0;

    virtual void Started() = 0;

    virtual void AudioStarted() = 0;

    virtual void SoundStarted() = 0;

    virtual void SoundEnded() = 0;

    virtual void AudioEnded() = 0;

    virtual void Ended() = 0;
};

//class BLINK_PLATFORM_EXPORT SpeechRecognizerProxy : public SpeechRecognizer {
//public:
//    using InterfaceType = SpeechRecognizer;
//
//    explicit SpeechRecognizerProxy(mojo::MessageReceiverWithResponder* receiver);
//
//    void Start(StartSpeechRecognitionRequestParamsPtr params) final;
//
//private:
//    mojo::MessageReceiverWithResponder* receiver_;
//};

//class BLINK_PLATFORM_EXPORT OnDeviceSpeechRecognitionProxy : public OnDeviceSpeechRecognition {
//public:
//    using InterfaceType = OnDeviceSpeechRecognition;
//
//    explicit OnDeviceSpeechRecognitionProxy(mojo::MessageReceiverWithResponder* receiver);
//
//    void OnDeviceWebSpeechAvailable(const WTF::String& language, OnDeviceWebSpeechAvailableCallback callback) final;
//
//    void InstallOnDeviceSpeechRecognition(const WTF::String& language, InstallOnDeviceSpeechRecognitionCallback callback) final;
//
//private:
//    mojo::MessageReceiverWithResponder* receiver_;
//};

//class BLINK_PLATFORM_EXPORT SpeechRecognitionSessionProxy : public SpeechRecognitionSession {
//public:
//    using InterfaceType = SpeechRecognitionSession;
//
//    explicit SpeechRecognitionSessionProxy(mojo::MessageReceiverWithResponder* receiver);
//
//    void Abort() final;
//
//    void StopCapture() final;
//
//private:
//    mojo::MessageReceiverWithResponder* receiver_;
//};

//class BLINK_PLATFORM_EXPORT SpeechRecognitionSessionClientProxy : public SpeechRecognitionSessionClient {
//public:
//    using InterfaceType = SpeechRecognitionSessionClient;
//
//    explicit SpeechRecognitionSessionClientProxy(mojo::MessageReceiverWithResponder* receiver);
//
//    void ResultRetrieved(WTF::Vector<::media::mojom::blink::WebSpeechRecognitionResultPtr> results) final;
//
//    void ErrorOccurred(::media::mojom::blink::SpeechRecognitionErrorPtr error) final;
//
//    void Started() final;
//
//    void AudioStarted() final;
//
//    void SoundStarted() final;
//
//    void SoundEnded() final;
//
//    void AudioEnded() final;
//
//    void Ended() final;
//
//private:
//    mojo::MessageReceiverWithResponder* receiver_;
//};
//class BLINK_PLATFORM_EXPORT SpeechRecognizerStubDispatch {
//public:
//    static bool Accept(SpeechRecognizer* impl, mojo::Message* message);
//    static bool AcceptWithResponder(SpeechRecognizer* impl, mojo::Message* message, std::unique_ptr<mojo::MessageReceiverWithStatus> responder);
//};

//template <typename ImplRefTraits = mojo::RawPtrImplRefTraits<SpeechRecognizer>> class SpeechRecognizerStub : public mojo::MessageReceiverWithResponderStatus {
//public:
//    using ImplPointerType = typename ImplRefTraits::PointerType;
//
//    SpeechRecognizerStub() = default;
//    ~SpeechRecognizerStub() override = default;
//
//    void set_sink(ImplPointerType sink)
//    {
//        sink_ = std::move(sink);
//    }
//    ImplPointerType& sink()
//    {
//        return sink_;
//    }
//
//    bool Accept(mojo::Message* message) override
//    {
//        if (ImplRefTraits::IsNull(sink_))
//            return false;
//        return SpeechRecognizerStubDispatch::Accept(ImplRefTraits::GetRawPointer(&sink_), message);
//    }
//
//    bool AcceptWithResponder(mojo::Message* message, std::unique_ptr<mojo::MessageReceiverWithStatus> responder) override
//    {
//        if (ImplRefTraits::IsNull(sink_))
//            return false;
//        return SpeechRecognizerStubDispatch::AcceptWithResponder(ImplRefTraits::GetRawPointer(&sink_), message, std::move(responder));
//    }
//
//private:
//    ImplPointerType sink_;
//};
//class BLINK_PLATFORM_EXPORT OnDeviceSpeechRecognitionStubDispatch {
//public:
//    static bool Accept(OnDeviceSpeechRecognition* impl, mojo::Message* message);
//    static bool AcceptWithResponder(OnDeviceSpeechRecognition* impl, mojo::Message* message, std::unique_ptr<mojo::MessageReceiverWithStatus> responder);
//};

//template <typename ImplRefTraits = mojo::RawPtrImplRefTraits<OnDeviceSpeechRecognition>>
//class OnDeviceSpeechRecognitionStub : public mojo::MessageReceiverWithResponderStatus {
//public:
//    using ImplPointerType = typename ImplRefTraits::PointerType;
//
//    OnDeviceSpeechRecognitionStub() = default;
//    ~OnDeviceSpeechRecognitionStub() override = default;
//
//    void set_sink(ImplPointerType sink)
//    {
//        sink_ = std::move(sink);
//    }
//    ImplPointerType& sink()
//    {
//        return sink_;
//    }
//
//    bool Accept(mojo::Message* message) override
//    {
//        if (ImplRefTraits::IsNull(sink_))
//            return false;
//        return OnDeviceSpeechRecognitionStubDispatch::Accept(ImplRefTraits::GetRawPointer(&sink_), message);
//    }
//
//    bool AcceptWithResponder(mojo::Message* message, std::unique_ptr<mojo::MessageReceiverWithStatus> responder) override
//    {
//        if (ImplRefTraits::IsNull(sink_))
//            return false;
//        return OnDeviceSpeechRecognitionStubDispatch::AcceptWithResponder(ImplRefTraits::GetRawPointer(&sink_), message, std::move(responder));
//    }
//
//private:
//    ImplPointerType sink_;
//};
//class BLINK_PLATFORM_EXPORT SpeechRecognitionSessionStubDispatch {
//public:
//    static bool Accept(SpeechRecognitionSession* impl, mojo::Message* message);
//    static bool AcceptWithResponder(SpeechRecognitionSession* impl, mojo::Message* message, std::unique_ptr<mojo::MessageReceiverWithStatus> responder);
//};

//template <typename ImplRefTraits = mojo::RawPtrImplRefTraits<SpeechRecognitionSession>>
//class SpeechRecognitionSessionStub : public mojo::MessageReceiverWithResponderStatus {
//public:
//    using ImplPointerType = typename ImplRefTraits::PointerType;
//
//    SpeechRecognitionSessionStub() = default;
//    ~SpeechRecognitionSessionStub() override = default;
//
//    void set_sink(ImplPointerType sink)
//    {
//        sink_ = std::move(sink);
//    }
//    ImplPointerType& sink()
//    {
//        return sink_;
//    }
//
//    bool Accept(mojo::Message* message) override
//    {
//        if (ImplRefTraits::IsNull(sink_))
//            return false;
//        return SpeechRecognitionSessionStubDispatch::Accept(ImplRefTraits::GetRawPointer(&sink_), message);
//    }
//
//    bool AcceptWithResponder(mojo::Message* message, std::unique_ptr<mojo::MessageReceiverWithStatus> responder) override
//    {
//        if (ImplRefTraits::IsNull(sink_))
//            return false;
//        return SpeechRecognitionSessionStubDispatch::AcceptWithResponder(ImplRefTraits::GetRawPointer(&sink_), message, std::move(responder));
//    }
//
//private:
//    ImplPointerType sink_;
//};
//class BLINK_PLATFORM_EXPORT SpeechRecognitionSessionClientStubDispatch {
//public:
//    static bool Accept(SpeechRecognitionSessionClient* impl, mojo::Message* message);
//    static bool AcceptWithResponder(SpeechRecognitionSessionClient* impl, mojo::Message* message, std::unique_ptr<mojo::MessageReceiverWithStatus> responder);
//};

//template <typename ImplRefTraits = mojo::RawPtrImplRefTraits<SpeechRecognitionSessionClient>>
//class SpeechRecognitionSessionClientStub : public mojo::MessageReceiverWithResponderStatus {
//public:
//    using ImplPointerType = typename ImplRefTraits::PointerType;
//
//    SpeechRecognitionSessionClientStub() = default;
//    ~SpeechRecognitionSessionClientStub() override = default;
//
//    void set_sink(ImplPointerType sink)
//    {
//        sink_ = std::move(sink);
//    }
//    ImplPointerType& sink()
//    {
//        return sink_;
//    }
//
//    bool Accept(mojo::Message* message) override
//    {
//        if (ImplRefTraits::IsNull(sink_))
//            return false;
//        return SpeechRecognitionSessionClientStubDispatch::Accept(ImplRefTraits::GetRawPointer(&sink_), message);
//    }
//
//    bool AcceptWithResponder(mojo::Message* message, std::unique_ptr<mojo::MessageReceiverWithStatus> responder) override
//    {
//        if (ImplRefTraits::IsNull(sink_))
//            return false;
//        return SpeechRecognitionSessionClientStubDispatch::AcceptWithResponder(ImplRefTraits::GetRawPointer(&sink_), message, std::move(responder));
//    }
//
//private:
//    ImplPointerType sink_;
//};
//class BLINK_PLATFORM_EXPORT SpeechRecognizerRequestValidator : public mojo::MessageReceiver {
//public:
//    bool Accept(mojo::Message* message) override;
//};
//class BLINK_PLATFORM_EXPORT OnDeviceSpeechRecognitionRequestValidator : public mojo::MessageReceiver {
//public:
//    bool Accept(mojo::Message* message) override;
//};
//class BLINK_PLATFORM_EXPORT SpeechRecognitionSessionRequestValidator : public mojo::MessageReceiver {
//public:
//    bool Accept(mojo::Message* message) override;
//};
//class BLINK_PLATFORM_EXPORT SpeechRecognitionSessionClientRequestValidator : public mojo::MessageReceiver {
//public:
//    bool Accept(mojo::Message* message) override;
//};
//class BLINK_PLATFORM_EXPORT OnDeviceSpeechRecognitionResponseValidator : public mojo::MessageReceiver {
//public:
//    bool Accept(mojo::Message* message) override;
//};

class BLINK_PLATFORM_EXPORT StartSpeechRecognitionRequestParams {
public:
    template <typename T> using EnableIfSame = std::enable_if_t<std::is_same<StartSpeechRecognitionRequestParams, T>::value>;
    using DataView = StartSpeechRecognitionRequestParamsDataView;
    using Data_ = internal::StartSpeechRecognitionRequestParams_Data;

    template <typename... Args> static StartSpeechRecognitionRequestParamsPtr New(Args&&... args)
    {
        return StartSpeechRecognitionRequestParamsPtr(std::in_place, std::forward<Args>(args)...);
    }

    template <typename U> static StartSpeechRecognitionRequestParamsPtr From(const U& u)
    {
        return mojo::TypeConverter<StartSpeechRecognitionRequestParamsPtr, U>::Convert(u);
    }

    template <typename U> U To() const
    {
        return mojo::TypeConverter<U, StartSpeechRecognitionRequestParams>::Convert(*this);
    }

    StartSpeechRecognitionRequestParams()
    : session_receiver()
    , client()
    , language()
    , grammars()
    , max_hypotheses()
    , continuous()
    , interim_results()
    , on_device()
    , allow_cloud_fallback()
    , audio_forwarder()
    , channel_count()
    , sample_rate()
{
}

    StartSpeechRecognitionRequestParams(::mojo::PendingReceiver<SpeechRecognitionSession> session_receiver_in,
    ::mojo::PendingRemote<SpeechRecognitionSessionClient> client_in, const WTF::String& language_in,
    WTF::Vector<::media::mojom::blink::SpeechRecognitionGrammarPtr> grammars_in, uint32_t max_hypotheses_in, bool continuous_in, bool interim_results_in,
    bool on_device_in, bool allow_cloud_fallback_in, ::mojo::PendingReceiver<::media::mojom::blink::SpeechRecognitionAudioForwarder> audio_forwarder_in,
    int32_t channel_count_in, int32_t sample_rate_in)
    : session_receiver(std::move(session_receiver_in))
    , client(std::move(client_in))
    , language(std::move(language_in))
    , grammars(std::move(grammars_in))
    , max_hypotheses(std::move(max_hypotheses_in))
    , continuous(std::move(continuous_in))
    , interim_results(std::move(interim_results_in))
    , on_device(std::move(on_device_in))
    , allow_cloud_fallback(std::move(allow_cloud_fallback_in))
    , audio_forwarder(std::move(audio_forwarder_in))
    , channel_count(std::move(channel_count_in))
    , sample_rate(std::move(sample_rate_in)){
}

    StartSpeechRecognitionRequestParams(const StartSpeechRecognitionRequestParams&) = delete;
    StartSpeechRecognitionRequestParams& operator=(const StartSpeechRecognitionRequestParams&) = delete;

    ~StartSpeechRecognitionRequestParams() = default;

    // Clone() is a template so it is only instantiated if it is used. Thus, the
    // bindings generator does not need to know whether Clone() or copy
    // constructor/assignment are available for members.
    template <typename StructPtrType = StartSpeechRecognitionRequestParamsPtr> StartSpeechRecognitionRequestParamsPtr Clone() const;

    // Equals() is a template so it is only instantiated if it is used. Thus, the
    // bindings generator does not need to know whether Equals() or == operator
    // are available for members.
    template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>* = nullptr> bool Equals(const T& other) const;

    template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>* = nullptr> bool operator==(const T& rhs) const
    {
        return Equals(rhs);
    }

    template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>* = nullptr> bool operator!=(const T& rhs) const
    {
        return !operator==(rhs);
    }

    template <typename UserType> static mojo::Message SerializeAsMessage(UserType* input)
    {
        return mojo::internal::SerializeAsMessageImpl<StartSpeechRecognitionRequestParams::DataView>(input);
    }

    // The returned Message is serialized only if the message is moved
    // cross-process or cross-language. Otherwise if the message is Deserialized
    // as the same UserType |input| will just be moved to |output| in
    // DeserializeFromMessage.
    template <typename UserType> static mojo::Message WrapAsMessage(UserType input)
    {
        return mojo::Message(
            std::make_unique<internal::StartSpeechRecognitionRequestParams_UnserializedMessageContext<UserType, StartSpeechRecognitionRequestParams::DataView>>(
                0, 0, std::move(input)),
            MOJO_CREATE_MESSAGE_FLAG_NONE);
    }

    template <typename UserType> static bool Deserialize(const void* data, size_t data_num_bytes, UserType* output)
    {
        mojo::Message message;
        return mojo::internal::DeserializeImpl<StartSpeechRecognitionRequestParams::DataView>(message, data, data_num_bytes, output, Validate);
    }

    template <typename UserType> static bool Deserialize(base::span<const uint8_t> input, UserType* output)
    {
        return StartSpeechRecognitionRequestParams::Deserialize(input.empty() ? nullptr : input.data(), input.size(), output);
    }

    template <typename UserType> static bool DeserializeFromMessage(mojo::Message input, UserType* output)
    {
        auto context = input.TakeUnserializedContext<
            internal::StartSpeechRecognitionRequestParams_UnserializedMessageContext<UserType, StartSpeechRecognitionRequestParams::DataView>>();
        if (context) {
            *output = std::move(context->TakeData());
            return true;
        }
        input.SerializeIfNecessary();
        return mojo::internal::DeserializeImpl<StartSpeechRecognitionRequestParams::DataView>(
            input, input.payload(), input.payload_num_bytes(), output, Validate);
    }

    ::mojo::PendingReceiver<SpeechRecognitionSession> session_receiver;

    ::mojo::PendingRemote<SpeechRecognitionSessionClient> client;

    WTF::String language;

    WTF::Vector<::media::mojom::blink::SpeechRecognitionGrammarPtr> grammars;

    uint32_t max_hypotheses;

    bool continuous;

    bool interim_results;

    bool on_device;

    bool allow_cloud_fallback;

    ::mojo::PendingReceiver<::media::mojom::blink::SpeechRecognitionAudioForwarder> audio_forwarder;

    int32_t channel_count;

    int32_t sample_rate;

    // Serialise this struct into a trace.
    void WriteIntoTrace(perfetto::TracedValue traced_context) const;

private:
    static bool Validate(const void* data, mojo::internal::ValidationContext* validation_context);
};

// The comparison operators are templates, so they are only instantiated if they
// are used. Thus, the bindings generator does not need to know whether
// comparison operators are available for members.
template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>* = nullptr> bool operator<(const T& lhs, const T& rhs);

template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>* = nullptr> bool operator<=(const T& lhs, const T& rhs)
{
    return !(rhs < lhs);
}

template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>* = nullptr> bool operator>(const T& lhs, const T& rhs)
{
    return rhs < lhs;
}

template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>* = nullptr> bool operator>=(const T& lhs, const T& rhs)
{
    return !(lhs < rhs);
}

template <typename StructPtrType> StartSpeechRecognitionRequestParamsPtr StartSpeechRecognitionRequestParams::Clone() const
{
    return New(mojo::Clone(session_receiver), mojo::Clone(client), mojo::Clone(language), mojo::Clone(grammars), mojo::Clone(max_hypotheses),
        mojo::Clone(continuous), mojo::Clone(interim_results), mojo::Clone(on_device), mojo::Clone(allow_cloud_fallback), mojo::Clone(audio_forwarder),
        mojo::Clone(channel_count), mojo::Clone(sample_rate));
}

template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>*> bool StartSpeechRecognitionRequestParams::Equals(const T& other_struct) const
{
    if (!mojo::Equals(this->session_receiver, other_struct.session_receiver))
        return false;
    if (!mojo::Equals(this->client, other_struct.client))
        return false;
    if (!mojo::Equals(this->language, other_struct.language))
        return false;
    if (!mojo::Equals(this->grammars, other_struct.grammars))
        return false;
    if (!mojo::Equals(this->max_hypotheses, other_struct.max_hypotheses))
        return false;
    if (!mojo::Equals(this->continuous, other_struct.continuous))
        return false;
    if (!mojo::Equals(this->interim_results, other_struct.interim_results))
        return false;
    if (!mojo::Equals(this->on_device, other_struct.on_device))
        return false;
    if (!mojo::Equals(this->allow_cloud_fallback, other_struct.allow_cloud_fallback))
        return false;
    if (!mojo::Equals(this->audio_forwarder, other_struct.audio_forwarder))
        return false;
    if (!mojo::Equals(this->channel_count, other_struct.channel_count))
        return false;
    if (!mojo::Equals(this->sample_rate, other_struct.sample_rate))
        return false;
    return true;
}

template <typename T, StartSpeechRecognitionRequestParams::EnableIfSame<T>*> bool operator<(const T& lhs, const T& rhs)
{
    if (lhs.session_receiver < rhs.session_receiver)
        return true;
    if (rhs.session_receiver < lhs.session_receiver)
        return false;
    if (lhs.client < rhs.client)
        return true;
    if (rhs.client < lhs.client)
        return false;
    if (lhs.language < rhs.language)
        return true;
    if (rhs.language < lhs.language)
        return false;
    if (lhs.grammars < rhs.grammars)
        return true;
    if (rhs.grammars < lhs.grammars)
        return false;
    if (lhs.max_hypotheses < rhs.max_hypotheses)
        return true;
    if (rhs.max_hypotheses < lhs.max_hypotheses)
        return false;
    if (lhs.continuous < rhs.continuous)
        return true;
    if (rhs.continuous < lhs.continuous)
        return false;
    if (lhs.interim_results < rhs.interim_results)
        return true;
    if (rhs.interim_results < lhs.interim_results)
        return false;
    if (lhs.on_device < rhs.on_device)
        return true;
    if (rhs.on_device < lhs.on_device)
        return false;
    if (lhs.allow_cloud_fallback < rhs.allow_cloud_fallback)
        return true;
    if (rhs.allow_cloud_fallback < lhs.allow_cloud_fallback)
        return false;
    if (lhs.audio_forwarder < rhs.audio_forwarder)
        return true;
    if (rhs.audio_forwarder < lhs.audio_forwarder)
        return false;
    if (lhs.channel_count < rhs.channel_count)
        return true;
    if (rhs.channel_count < lhs.channel_count)
        return false;
    if (lhs.sample_rate < rhs.sample_rate)
        return true;
    if (rhs.sample_rate < lhs.sample_rate)
        return false;
    return false;
}

} // media::mojom::blink

namespace mojo {

template <>
struct BLINK_PLATFORM_EXPORT
    StructTraits<::media::mojom::blink::StartSpeechRecognitionRequestParams::DataView, ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr> {
    static bool IsNull(const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return !input;
    }
    static void SetToNull(::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr* output)
    {
        output->reset();
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::session_receiver)& session_receiver(
        ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->session_receiver;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::client)& client(
        ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->client;
    }

    static const decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::language)& language(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->language;
    }

    static const decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::grammars)& grammars(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->grammars;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::max_hypotheses) max_hypotheses(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->max_hypotheses;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::continuous) continuous(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->continuous;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::interim_results) interim_results(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->interim_results;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::on_device) on_device(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->on_device;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::allow_cloud_fallback) allow_cloud_fallback(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->allow_cloud_fallback;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::audio_forwarder)& audio_forwarder(
        ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->audio_forwarder;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::channel_count) channel_count(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->channel_count;
    }

    static decltype(::media::mojom::blink::StartSpeechRecognitionRequestParams::sample_rate) sample_rate(
        const ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr& input)
    {
        return input->sample_rate;
    }

    static bool Read(
        ::media::mojom::blink::StartSpeechRecognitionRequestParams::DataView input, ::media::mojom::blink::StartSpeechRecognitionRequestParamsPtr* output);
};

} // namespace mojo

#endif // MEDIA_MOJO_MOJOM_SPEECH_RECOGNIZER_MOJOM_BLINK_H_
