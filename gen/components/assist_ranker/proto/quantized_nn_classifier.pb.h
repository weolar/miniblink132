// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: quantized_nn_classifier.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_quantized_5fnn_5fclassifier_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_quantized_5fnn_5fclassifier_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3021000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3021012 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata_lite.h>
#include <google/protobuf/message_lite.h>
#include <google/protobuf/repeated_field.h> // IWYU pragma: export
#include <google/protobuf/extension_set.h> // IWYU pragma: export
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_quantized_5fnn_5fclassifier_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
} // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_quantized_5fnn_5fclassifier_2eproto {
    static const uint32_t offsets[];
};
namespace assist_ranker {
class QuantizedNNClassifierModel;
struct QuantizedNNClassifierModelDefaultTypeInternal;
extern QuantizedNNClassifierModelDefaultTypeInternal _QuantizedNNClassifierModel_default_instance_;
class QuantizedNNLayer;
struct QuantizedNNLayerDefaultTypeInternal;
extern QuantizedNNLayerDefaultTypeInternal _QuantizedNNLayer_default_instance_;
} // namespace assist_ranker
PROTOBUF_NAMESPACE_OPEN
template <>::assist_ranker::QuantizedNNClassifierModel* Arena::CreateMaybeMessage<::assist_ranker::QuantizedNNClassifierModel>(Arena*);
template <>::assist_ranker::QuantizedNNLayer* Arena::CreateMaybeMessage<::assist_ranker::QuantizedNNLayer>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace assist_ranker {

// ===================================================================

class QuantizedNNLayer final : public ::PROTOBUF_NAMESPACE_ID::MessageLite /* @@protoc_insertion_point(class_definition:assist_ranker.QuantizedNNLayer) */ {
public:
    inline QuantizedNNLayer()
        : QuantizedNNLayer(nullptr)
    {
    }
    ~QuantizedNNLayer() override;
    explicit PROTOBUF_CONSTEXPR QuantizedNNLayer(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

    QuantizedNNLayer(const QuantizedNNLayer& from);
    QuantizedNNLayer(QuantizedNNLayer&& from) noexcept
        : QuantizedNNLayer()
    {
        *this = ::std::move(from);
    }

    inline QuantizedNNLayer& operator=(const QuantizedNNLayer& from)
    {
        CopyFrom(from);
        return *this;
    }
    inline QuantizedNNLayer& operator=(QuantizedNNLayer&& from) noexcept
    {
        if (this == &from)
            return *this;
        if (GetOwningArena() == from.GetOwningArena()
#ifdef PROTOBUF_FORCE_COPY_IN_MOVE
            && GetOwningArena() != nullptr
#endif // !PROTOBUF_FORCE_COPY_IN_MOVE
        ) {
            InternalSwap(&from);
        } else {
            CopyFrom(from);
        }
        return *this;
    }

    inline const std::string& unknown_fields() const
    {
        return _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString);
    }
    inline std::string* mutable_unknown_fields()
    {
        return _internal_metadata_.mutable_unknown_fields<std::string>();
    }

    static const QuantizedNNLayer& default_instance()
    {
        return *internal_default_instance();
    }
    static inline const QuantizedNNLayer* internal_default_instance()
    {
        return reinterpret_cast<const QuantizedNNLayer*>(&_QuantizedNNLayer_default_instance_);
    }
    static constexpr int kIndexInFileMessages = 0;

    friend void swap(QuantizedNNLayer& a, QuantizedNNLayer& b)
    {
        a.Swap(&b);
    }
    PROTOBUF_NOINLINE void Swap(QuantizedNNLayer* other)
    {
        if (other == this)
            return;
#ifdef PROTOBUF_FORCE_COPY_IN_SWAP
        if (GetOwningArena() != nullptr && GetOwningArena() == other->GetOwningArena()) {
#else // PROTOBUF_FORCE_COPY_IN_SWAP
        if (GetOwningArena() == other->GetOwningArena()) {
#endif // !PROTOBUF_FORCE_COPY_IN_SWAP
            InternalSwap(other);
        } else {
            ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
        }
    }
    void UnsafeArenaSwap(QuantizedNNLayer* other)
    {
        if (other == this)
            return;
        GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
        InternalSwap(other);
    }

    // implements Message ----------------------------------------------

    QuantizedNNLayer* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final
    {
        return CreateMaybeMessage<QuantizedNNLayer>(arena);
    }
    void CheckTypeAndMergeFrom(const ::PROTOBUF_NAMESPACE_ID::MessageLite& from) final;
    void CopyFrom(const QuantizedNNLayer& from);
    void MergeFrom(const QuantizedNNLayer& from);
    PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
    bool IsInitialized() const final;

    size_t ByteSizeLong() const final;
    const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
    uint8_t* _InternalSerialize(uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
    int GetCachedSize() const final
    {
        return _impl_._cached_size_.Get();
    }

private:
    void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
    void SharedDtor();
    void SetCachedSize(int size) const;
    void InternalSwap(QuantizedNNLayer* other);

private:
    friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
    static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName()
    {
        return "assist_ranker.QuantizedNNLayer";
    }

protected:
    explicit QuantizedNNLayer(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned = false);

public:
    std::string GetTypeName() const final;

    // nested types ----------------------------------------------------

    // accessors -------------------------------------------------------

    enum : int {
        kWeightsFieldNumber = 1,
        kBiasesFieldNumber = 2,
        kLowFieldNumber = 3,
        kHighFieldNumber = 4,
    };
    // repeated bytes weights = 1;
    int weights_size() const;

private:
    int _internal_weights_size() const;

public:
    void clear_weights();
    const std::string& weights(int index) const;
    std::string* mutable_weights(int index);
    void set_weights(int index, const std::string& value);
    void set_weights(int index, std::string&& value);
    void set_weights(int index, const char* value);
    void set_weights(int index, const void* value, size_t size);
    std::string* add_weights();
    void add_weights(const std::string& value);
    void add_weights(std::string&& value);
    void add_weights(const char* value);
    void add_weights(const void* value, size_t size);
    const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>& weights() const;
    ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>* mutable_weights();

private:
    const std::string& _internal_weights(int index) const;
    std::string* _internal_add_weights();

public:
    // optional bytes biases = 2;
    bool has_biases() const;

private:
    bool _internal_has_biases() const;

public:
    void clear_biases();
    const std::string& biases() const;
    template <typename ArgT0 = const std::string&, typename... ArgT> void set_biases(ArgT0&& arg0, ArgT... args);
    std::string* mutable_biases();
    PROTOBUF_NODISCARD std::string* release_biases();
    void set_allocated_biases(std::string* biases);

private:
    const std::string& _internal_biases() const;
    inline PROTOBUF_ALWAYS_INLINE void _internal_set_biases(const std::string& value);
    std::string* _internal_mutable_biases();

public:
    // optional float low = 3;
    bool has_low() const;

private:
    bool _internal_has_low() const;

public:
    void clear_low();
    float low() const;
    void set_low(float value);

private:
    float _internal_low() const;
    void _internal_set_low(float value);

public:
    // optional float high = 4;
    bool has_high() const;

private:
    bool _internal_has_high() const;

public:
    void clear_high();
    float high() const;
    void set_high(float value);

private:
    float _internal_high() const;
    void _internal_set_high(float value);

public:
    // @@protoc_insertion_point(class_scope:assist_ranker.QuantizedNNLayer)
private:
    class _Internal;

    template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
    typedef void InternalArenaConstructable_;
    typedef void DestructorSkippable_;
    struct Impl_ {
        ::PROTOBUF_NAMESPACE_ID::internal::HasBits<1> _has_bits_;
        mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
        ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string> weights_;
        ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr biases_;
        float low_;
        float high_;
    };
    union {
        Impl_ _impl_;
    };
    friend struct ::TableStruct_quantized_5fnn_5fclassifier_2eproto;
};
// -------------------------------------------------------------------

class QuantizedNNClassifierModel final
    : public ::PROTOBUF_NAMESPACE_ID::MessageLite /* @@protoc_insertion_point(class_definition:assist_ranker.QuantizedNNClassifierModel) */ {
public:
    inline QuantizedNNClassifierModel()
        : QuantizedNNClassifierModel(nullptr)
    {
    }
    ~QuantizedNNClassifierModel() override;
    explicit PROTOBUF_CONSTEXPR QuantizedNNClassifierModel(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

    QuantizedNNClassifierModel(const QuantizedNNClassifierModel& from);
    QuantizedNNClassifierModel(QuantizedNNClassifierModel&& from) noexcept
        : QuantizedNNClassifierModel()
    {
        *this = ::std::move(from);
    }

    inline QuantizedNNClassifierModel& operator=(const QuantizedNNClassifierModel& from)
    {
        CopyFrom(from);
        return *this;
    }
    inline QuantizedNNClassifierModel& operator=(QuantizedNNClassifierModel&& from) noexcept
    {
        if (this == &from)
            return *this;
        if (GetOwningArena() == from.GetOwningArena()
#ifdef PROTOBUF_FORCE_COPY_IN_MOVE
            && GetOwningArena() != nullptr
#endif // !PROTOBUF_FORCE_COPY_IN_MOVE
        ) {
            InternalSwap(&from);
        } else {
            CopyFrom(from);
        }
        return *this;
    }

    inline const std::string& unknown_fields() const
    {
        return _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString);
    }
    inline std::string* mutable_unknown_fields()
    {
        return _internal_metadata_.mutable_unknown_fields<std::string>();
    }

    static const QuantizedNNClassifierModel& default_instance()
    {
        return *internal_default_instance();
    }
    static inline const QuantizedNNClassifierModel* internal_default_instance()
    {
        return reinterpret_cast<const QuantizedNNClassifierModel*>(&_QuantizedNNClassifierModel_default_instance_);
    }
    static constexpr int kIndexInFileMessages = 1;

    friend void swap(QuantizedNNClassifierModel& a, QuantizedNNClassifierModel& b)
    {
        a.Swap(&b);
    }
    PROTOBUF_NOINLINE void Swap(QuantizedNNClassifierModel* other)
    {
        if (other == this)
            return;
#ifdef PROTOBUF_FORCE_COPY_IN_SWAP
        if (GetOwningArena() != nullptr && GetOwningArena() == other->GetOwningArena()) {
#else // PROTOBUF_FORCE_COPY_IN_SWAP
        if (GetOwningArena() == other->GetOwningArena()) {
#endif // !PROTOBUF_FORCE_COPY_IN_SWAP
            InternalSwap(other);
        } else {
            ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
        }
    }
    void UnsafeArenaSwap(QuantizedNNClassifierModel* other)
    {
        if (other == this)
            return;
        GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
        InternalSwap(other);
    }

    // implements Message ----------------------------------------------

    QuantizedNNClassifierModel* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final
    {
        return CreateMaybeMessage<QuantizedNNClassifierModel>(arena);
    }
    void CheckTypeAndMergeFrom(const ::PROTOBUF_NAMESPACE_ID::MessageLite& from) final;
    void CopyFrom(const QuantizedNNClassifierModel& from);
    void MergeFrom(const QuantizedNNClassifierModel& from);
    PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
    bool IsInitialized() const final;

    size_t ByteSizeLong() const final;
    const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
    uint8_t* _InternalSerialize(uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
    int GetCachedSize() const final
    {
        return _impl_._cached_size_.Get();
    }

private:
    void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned);
    void SharedDtor();
    void SetCachedSize(int size) const;
    void InternalSwap(QuantizedNNClassifierModel* other);

private:
    friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
    static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName()
    {
        return "assist_ranker.QuantizedNNClassifierModel";
    }

protected:
    explicit QuantizedNNClassifierModel(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned = false);

public:
    std::string GetTypeName() const final;

    // nested types ----------------------------------------------------

    // accessors -------------------------------------------------------

    enum : int {
        kHiddenLayerFieldNumber = 1,
        kLogitsLayerFieldNumber = 2,
    };
    // optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
    bool has_hidden_layer() const;

private:
    bool _internal_has_hidden_layer() const;

public:
    void clear_hidden_layer();
    const ::assist_ranker::QuantizedNNLayer& hidden_layer() const;
    PROTOBUF_NODISCARD ::assist_ranker::QuantizedNNLayer* release_hidden_layer();
    ::assist_ranker::QuantizedNNLayer* mutable_hidden_layer();
    void set_allocated_hidden_layer(::assist_ranker::QuantizedNNLayer* hidden_layer);

private:
    const ::assist_ranker::QuantizedNNLayer& _internal_hidden_layer() const;
    ::assist_ranker::QuantizedNNLayer* _internal_mutable_hidden_layer();

public:
    void unsafe_arena_set_allocated_hidden_layer(::assist_ranker::QuantizedNNLayer* hidden_layer);
    ::assist_ranker::QuantizedNNLayer* unsafe_arena_release_hidden_layer();

    // optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
    bool has_logits_layer() const;

private:
    bool _internal_has_logits_layer() const;

public:
    void clear_logits_layer();
    const ::assist_ranker::QuantizedNNLayer& logits_layer() const;
    PROTOBUF_NODISCARD ::assist_ranker::QuantizedNNLayer* release_logits_layer();
    ::assist_ranker::QuantizedNNLayer* mutable_logits_layer();
    void set_allocated_logits_layer(::assist_ranker::QuantizedNNLayer* logits_layer);

private:
    const ::assist_ranker::QuantizedNNLayer& _internal_logits_layer() const;
    ::assist_ranker::QuantizedNNLayer* _internal_mutable_logits_layer();

public:
    void unsafe_arena_set_allocated_logits_layer(::assist_ranker::QuantizedNNLayer* logits_layer);
    ::assist_ranker::QuantizedNNLayer* unsafe_arena_release_logits_layer();

    // @@protoc_insertion_point(class_scope:assist_ranker.QuantizedNNClassifierModel)
private:
    class _Internal;

    template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
    typedef void InternalArenaConstructable_;
    typedef void DestructorSkippable_;
    struct Impl_ {
        ::PROTOBUF_NAMESPACE_ID::internal::HasBits<1> _has_bits_;
        mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
        ::assist_ranker::QuantizedNNLayer* hidden_layer_;
        ::assist_ranker::QuantizedNNLayer* logits_layer_;
    };
    union {
        Impl_ _impl_;
    };
    friend struct ::TableStruct_quantized_5fnn_5fclassifier_2eproto;
};
// ===================================================================

// ===================================================================

#ifdef __GNUC__
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif // __GNUC__
// QuantizedNNLayer

// repeated bytes weights = 1;
inline int QuantizedNNLayer::_internal_weights_size() const
{
    return _impl_.weights_.size();
}
inline int QuantizedNNLayer::weights_size() const
{
    return _internal_weights_size();
}
inline void QuantizedNNLayer::clear_weights()
{
    _impl_.weights_.Clear();
}
inline std::string* QuantizedNNLayer::add_weights()
{
    std::string* _s = _internal_add_weights();
    // @@protoc_insertion_point(field_add_mutable:assist_ranker.QuantizedNNLayer.weights)
    return _s;
}
inline const std::string& QuantizedNNLayer::_internal_weights(int index) const
{
    return _impl_.weights_.Get(index);
}
inline const std::string& QuantizedNNLayer::weights(int index) const
{
    // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNLayer.weights)
    return _internal_weights(index);
}
inline std::string* QuantizedNNLayer::mutable_weights(int index)
{
    // @@protoc_insertion_point(field_mutable:assist_ranker.QuantizedNNLayer.weights)
    return _impl_.weights_.Mutable(index);
}
inline void QuantizedNNLayer::set_weights(int index, const std::string& value)
{
    _impl_.weights_.Mutable(index)->assign(value);
    // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::set_weights(int index, std::string&& value)
{
    _impl_.weights_.Mutable(index)->assign(std::move(value));
    // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::set_weights(int index, const char* value)
{
    GOOGLE_DCHECK(value != nullptr);
    _impl_.weights_.Mutable(index)->assign(value);
    // @@protoc_insertion_point(field_set_char:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::set_weights(int index, const void* value, size_t size)
{
    _impl_.weights_.Mutable(index)->assign(reinterpret_cast<const char*>(value), size);
    // @@protoc_insertion_point(field_set_pointer:assist_ranker.QuantizedNNLayer.weights)
}
inline std::string* QuantizedNNLayer::_internal_add_weights()
{
    return _impl_.weights_.Add();
}
inline void QuantizedNNLayer::add_weights(const std::string& value)
{
    _impl_.weights_.Add()->assign(value);
    // @@protoc_insertion_point(field_add:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::add_weights(std::string&& value)
{
    _impl_.weights_.Add(std::move(value));
    // @@protoc_insertion_point(field_add:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::add_weights(const char* value)
{
    GOOGLE_DCHECK(value != nullptr);
    _impl_.weights_.Add()->assign(value);
    // @@protoc_insertion_point(field_add_char:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::add_weights(const void* value, size_t size)
{
    _impl_.weights_.Add()->assign(reinterpret_cast<const char*>(value), size);
    // @@protoc_insertion_point(field_add_pointer:assist_ranker.QuantizedNNLayer.weights)
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>& QuantizedNNLayer::weights() const
{
    // @@protoc_insertion_point(field_list:assist_ranker.QuantizedNNLayer.weights)
    return _impl_.weights_;
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>* QuantizedNNLayer::mutable_weights()
{
    // @@protoc_insertion_point(field_mutable_list:assist_ranker.QuantizedNNLayer.weights)
    return &_impl_.weights_;
}

// optional bytes biases = 2;
inline bool QuantizedNNLayer::_internal_has_biases() const
{
    bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
    return value;
}
inline bool QuantizedNNLayer::has_biases() const
{
    return _internal_has_biases();
}
inline void QuantizedNNLayer::clear_biases()
{
    _impl_.biases_.ClearToEmpty();
    _impl_._has_bits_[0] &= ~0x00000001u;
}
inline const std::string& QuantizedNNLayer::biases() const
{
    // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNLayer.biases)
    return _internal_biases();
}
template <typename ArgT0, typename... ArgT> inline PROTOBUF_ALWAYS_INLINE void QuantizedNNLayer::set_biases(ArgT0&& arg0, ArgT... args)
{
    _impl_._has_bits_[0] |= 0x00000001u;
    _impl_.biases_.SetBytes(static_cast<ArgT0&&>(arg0), args..., GetArenaForAllocation());
    // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.biases)
}
inline std::string* QuantizedNNLayer::mutable_biases()
{
    std::string* _s = _internal_mutable_biases();
    // @@protoc_insertion_point(field_mutable:assist_ranker.QuantizedNNLayer.biases)
    return _s;
}
inline const std::string& QuantizedNNLayer::_internal_biases() const
{
    return _impl_.biases_.Get();
}
inline void QuantizedNNLayer::_internal_set_biases(const std::string& value)
{
    _impl_._has_bits_[0] |= 0x00000001u;
    _impl_.biases_.Set(value, GetArenaForAllocation());
}
inline std::string* QuantizedNNLayer::_internal_mutable_biases()
{
    _impl_._has_bits_[0] |= 0x00000001u;
    return _impl_.biases_.Mutable(GetArenaForAllocation());
}
inline std::string* QuantizedNNLayer::release_biases()
{
    // @@protoc_insertion_point(field_release:assist_ranker.QuantizedNNLayer.biases)
    if (!_internal_has_biases()) {
        return nullptr;
    }
    _impl_._has_bits_[0] &= ~0x00000001u;
    auto* p = _impl_.biases_.Release();
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    if (_impl_.biases_.IsDefault()) {
        _impl_.biases_.Set("", GetArenaForAllocation());
    }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
    return p;
}
inline void QuantizedNNLayer::set_allocated_biases(std::string* biases)
{
    if (biases != nullptr) {
        _impl_._has_bits_[0] |= 0x00000001u;
    } else {
        _impl_._has_bits_[0] &= ~0x00000001u;
    }
    _impl_.biases_.SetAllocated(biases, GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    if (_impl_.biases_.IsDefault()) {
        _impl_.biases_.Set("", GetArenaForAllocation());
    }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
    // @@protoc_insertion_point(field_set_allocated:assist_ranker.QuantizedNNLayer.biases)
}

// optional float low = 3;
inline bool QuantizedNNLayer::_internal_has_low() const
{
    bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
    return value;
}
inline bool QuantizedNNLayer::has_low() const
{
    return _internal_has_low();
}
inline void QuantizedNNLayer::clear_low()
{
    _impl_.low_ = 0;
    _impl_._has_bits_[0] &= ~0x00000002u;
}
inline float QuantizedNNLayer::_internal_low() const
{
    return _impl_.low_;
}
inline float QuantizedNNLayer::low() const
{
    // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNLayer.low)
    return _internal_low();
}
inline void QuantizedNNLayer::_internal_set_low(float value)
{
    _impl_._has_bits_[0] |= 0x00000002u;
    _impl_.low_ = value;
}
inline void QuantizedNNLayer::set_low(float value)
{
    _internal_set_low(value);
    // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.low)
}

// optional float high = 4;
inline bool QuantizedNNLayer::_internal_has_high() const
{
    bool value = (_impl_._has_bits_[0] & 0x00000004u) != 0;
    return value;
}
inline bool QuantizedNNLayer::has_high() const
{
    return _internal_has_high();
}
inline void QuantizedNNLayer::clear_high()
{
    _impl_.high_ = 0;
    _impl_._has_bits_[0] &= ~0x00000004u;
}
inline float QuantizedNNLayer::_internal_high() const
{
    return _impl_.high_;
}
inline float QuantizedNNLayer::high() const
{
    // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNLayer.high)
    return _internal_high();
}
inline void QuantizedNNLayer::_internal_set_high(float value)
{
    _impl_._has_bits_[0] |= 0x00000004u;
    _impl_.high_ = value;
}
inline void QuantizedNNLayer::set_high(float value)
{
    _internal_set_high(value);
    // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.high)
}

// -------------------------------------------------------------------

// QuantizedNNClassifierModel

// optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
inline bool QuantizedNNClassifierModel::_internal_has_hidden_layer() const
{
    bool value = (_impl_._has_bits_[0] & 0x00000001u) != 0;
    PROTOBUF_ASSUME(!value || _impl_.hidden_layer_ != nullptr);
    return value;
}
inline bool QuantizedNNClassifierModel::has_hidden_layer() const
{
    return _internal_has_hidden_layer();
}
inline void QuantizedNNClassifierModel::clear_hidden_layer()
{
    if (_impl_.hidden_layer_ != nullptr)
        _impl_.hidden_layer_->Clear();
    _impl_._has_bits_[0] &= ~0x00000001u;
}
inline const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::_internal_hidden_layer() const
{
    const ::assist_ranker::QuantizedNNLayer* p = _impl_.hidden_layer_;
    return p != nullptr ? *p : reinterpret_cast<const ::assist_ranker::QuantizedNNLayer&>(::assist_ranker::_QuantizedNNLayer_default_instance_);
}
inline const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::hidden_layer() const
{
    // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
    return _internal_hidden_layer();
}
inline void QuantizedNNClassifierModel::unsafe_arena_set_allocated_hidden_layer(::assist_ranker::QuantizedNNLayer* hidden_layer)
{
    if (GetArenaForAllocation() == nullptr) {
        delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.hidden_layer_);
    }
    _impl_.hidden_layer_ = hidden_layer;
    if (hidden_layer) {
        _impl_._has_bits_[0] |= 0x00000001u;
    } else {
        _impl_._has_bits_[0] &= ~0x00000001u;
    }
    // @@protoc_insertion_point(field_unsafe_arena_set_allocated:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::release_hidden_layer()
{
    _impl_._has_bits_[0] &= ~0x00000001u;
    ::assist_ranker::QuantizedNNLayer* temp = _impl_.hidden_layer_;
    _impl_.hidden_layer_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
    auto* old = reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    if (GetArenaForAllocation() == nullptr) {
        delete old;
    }
#else // PROTOBUF_FORCE_COPY_IN_RELEASE
    if (GetArenaForAllocation() != nullptr) {
        temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    }
#endif // !PROTOBUF_FORCE_COPY_IN_RELEASE
    return temp;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::unsafe_arena_release_hidden_layer()
{
    // @@protoc_insertion_point(field_release:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
    _impl_._has_bits_[0] &= ~0x00000001u;
    ::assist_ranker::QuantizedNNLayer* temp = _impl_.hidden_layer_;
    _impl_.hidden_layer_ = nullptr;
    return temp;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::_internal_mutable_hidden_layer()
{
    _impl_._has_bits_[0] |= 0x00000001u;
    if (_impl_.hidden_layer_ == nullptr) {
        auto* p = CreateMaybeMessage<::assist_ranker::QuantizedNNLayer>(GetArenaForAllocation());
        _impl_.hidden_layer_ = p;
    }
    return _impl_.hidden_layer_;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::mutable_hidden_layer()
{
    ::assist_ranker::QuantizedNNLayer* _msg = _internal_mutable_hidden_layer();
    // @@protoc_insertion_point(field_mutable:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
    return _msg;
}
inline void QuantizedNNClassifierModel::set_allocated_hidden_layer(::assist_ranker::QuantizedNNLayer* hidden_layer)
{
    ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
    if (message_arena == nullptr) {
        delete _impl_.hidden_layer_;
    }
    if (hidden_layer) {
        ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena = ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(hidden_layer);
        if (message_arena != submessage_arena) {
            hidden_layer = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(message_arena, hidden_layer, submessage_arena);
        }
        _impl_._has_bits_[0] |= 0x00000001u;
    } else {
        _impl_._has_bits_[0] &= ~0x00000001u;
    }
    _impl_.hidden_layer_ = hidden_layer;
    // @@protoc_insertion_point(field_set_allocated:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
}

// optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
inline bool QuantizedNNClassifierModel::_internal_has_logits_layer() const
{
    bool value = (_impl_._has_bits_[0] & 0x00000002u) != 0;
    PROTOBUF_ASSUME(!value || _impl_.logits_layer_ != nullptr);
    return value;
}
inline bool QuantizedNNClassifierModel::has_logits_layer() const
{
    return _internal_has_logits_layer();
}
inline void QuantizedNNClassifierModel::clear_logits_layer()
{
    if (_impl_.logits_layer_ != nullptr)
        _impl_.logits_layer_->Clear();
    _impl_._has_bits_[0] &= ~0x00000002u;
}
inline const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::_internal_logits_layer() const
{
    const ::assist_ranker::QuantizedNNLayer* p = _impl_.logits_layer_;
    return p != nullptr ? *p : reinterpret_cast<const ::assist_ranker::QuantizedNNLayer&>(::assist_ranker::_QuantizedNNLayer_default_instance_);
}
inline const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::logits_layer() const
{
    // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNClassifierModel.logits_layer)
    return _internal_logits_layer();
}
inline void QuantizedNNClassifierModel::unsafe_arena_set_allocated_logits_layer(::assist_ranker::QuantizedNNLayer* logits_layer)
{
    if (GetArenaForAllocation() == nullptr) {
        delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(_impl_.logits_layer_);
    }
    _impl_.logits_layer_ = logits_layer;
    if (logits_layer) {
        _impl_._has_bits_[0] |= 0x00000002u;
    } else {
        _impl_._has_bits_[0] &= ~0x00000002u;
    }
    // @@protoc_insertion_point(field_unsafe_arena_set_allocated:assist_ranker.QuantizedNNClassifierModel.logits_layer)
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::release_logits_layer()
{
    _impl_._has_bits_[0] &= ~0x00000002u;
    ::assist_ranker::QuantizedNNLayer* temp = _impl_.logits_layer_;
    _impl_.logits_layer_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
    auto* old = reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    if (GetArenaForAllocation() == nullptr) {
        delete old;
    }
#else // PROTOBUF_FORCE_COPY_IN_RELEASE
    if (GetArenaForAllocation() != nullptr) {
        temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
    }
#endif // !PROTOBUF_FORCE_COPY_IN_RELEASE
    return temp;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::unsafe_arena_release_logits_layer()
{
    // @@protoc_insertion_point(field_release:assist_ranker.QuantizedNNClassifierModel.logits_layer)
    _impl_._has_bits_[0] &= ~0x00000002u;
    ::assist_ranker::QuantizedNNLayer* temp = _impl_.logits_layer_;
    _impl_.logits_layer_ = nullptr;
    return temp;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::_internal_mutable_logits_layer()
{
    _impl_._has_bits_[0] |= 0x00000002u;
    if (_impl_.logits_layer_ == nullptr) {
        auto* p = CreateMaybeMessage<::assist_ranker::QuantizedNNLayer>(GetArenaForAllocation());
        _impl_.logits_layer_ = p;
    }
    return _impl_.logits_layer_;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::mutable_logits_layer()
{
    ::assist_ranker::QuantizedNNLayer* _msg = _internal_mutable_logits_layer();
    // @@protoc_insertion_point(field_mutable:assist_ranker.QuantizedNNClassifierModel.logits_layer)
    return _msg;
}
inline void QuantizedNNClassifierModel::set_allocated_logits_layer(::assist_ranker::QuantizedNNLayer* logits_layer)
{
    ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
    if (message_arena == nullptr) {
        delete _impl_.logits_layer_;
    }
    if (logits_layer) {
        ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena = ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(logits_layer);
        if (message_arena != submessage_arena) {
            logits_layer = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(message_arena, logits_layer, submessage_arena);
        }
        _impl_._has_bits_[0] |= 0x00000002u;
    } else {
        _impl_._has_bits_[0] &= ~0x00000002u;
    }
    _impl_.logits_layer_ = logits_layer;
    // @@protoc_insertion_point(field_set_allocated:assist_ranker.QuantizedNNClassifierModel.logits_layer)
}

#ifdef __GNUC__
#pragma GCC diagnostic pop
#endif // __GNUC__
// -------------------------------------------------------------------

// @@protoc_insertion_point(namespace_scope)

} // namespace assist_ranker

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_quantized_5fnn_5fclassifier_2eproto
