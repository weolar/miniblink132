// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: quantized_nn_classifier.proto

#include "quantized_nn_classifier.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/io/zero_copy_stream_impl_lite.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace assist_ranker {
PROTOBUF_CONSTEXPR QuantizedNNLayer::QuantizedNNLayer(::_pbi::ConstantInitialized)
    : _impl_ { /*decltype(_impl_._has_bits_)*/ {}, /*decltype(_impl_._cached_size_)*/ {}, /*decltype(_impl_.weights_)*/ {},
        /*decltype(_impl_.biases_)*/ { &::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized {} }, /*decltype(_impl_.low_)*/ 0,
        /*decltype(_impl_.high_)*/ 0 }
{
}
struct QuantizedNNLayerDefaultTypeInternal {
    PROTOBUF_CONSTEXPR QuantizedNNLayerDefaultTypeInternal()
        : _instance(::_pbi::ConstantInitialized {})
    {
    }
    ~QuantizedNNLayerDefaultTypeInternal()
    {
    }
    union {
        QuantizedNNLayer _instance;
    };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 QuantizedNNLayerDefaultTypeInternal _QuantizedNNLayer_default_instance_;
PROTOBUF_CONSTEXPR QuantizedNNClassifierModel::QuantizedNNClassifierModel(::_pbi::ConstantInitialized)
    : _impl_ { /*decltype(_impl_._has_bits_)*/ {}, /*decltype(_impl_._cached_size_)*/ {}, /*decltype(_impl_.hidden_layer_)*/ nullptr,
        /*decltype(_impl_.logits_layer_)*/ nullptr }
{
}
struct QuantizedNNClassifierModelDefaultTypeInternal {
    PROTOBUF_CONSTEXPR QuantizedNNClassifierModelDefaultTypeInternal()
        : _instance(::_pbi::ConstantInitialized {})
    {
    }
    ~QuantizedNNClassifierModelDefaultTypeInternal()
    {
    }
    union {
        QuantizedNNClassifierModel _instance;
    };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 QuantizedNNClassifierModelDefaultTypeInternal
    _QuantizedNNClassifierModel_default_instance_;
} // namespace assist_ranker
namespace assist_ranker {

// ===================================================================

class QuantizedNNLayer::_Internal {
public:
    using HasBits = decltype(std::declval<QuantizedNNLayer>()._impl_._has_bits_);
    static void set_has_biases(HasBits* has_bits)
    {
        (*has_bits)[0] |= 1u;
    }
    static void set_has_low(HasBits* has_bits)
    {
        (*has_bits)[0] |= 2u;
    }
    static void set_has_high(HasBits* has_bits)
    {
        (*has_bits)[0] |= 4u;
    }
};

QuantizedNNLayer::QuantizedNNLayer(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned)
    : ::PROTOBUF_NAMESPACE_ID::MessageLite(arena, is_message_owned)
{
    SharedCtor(arena, is_message_owned);
    // @@protoc_insertion_point(arena_constructor:assist_ranker.QuantizedNNLayer)
}
QuantizedNNLayer::QuantizedNNLayer(const QuantizedNNLayer& from)
    : ::PROTOBUF_NAMESPACE_ID::MessageLite()
{
    QuantizedNNLayer* const _this = this;
    (void)_this;
    new (&_impl_) Impl_ { decltype(_impl_._has_bits_) { from._impl_._has_bits_ }, /*decltype(_impl_._cached_size_)*/ {},
        decltype(_impl_.weights_) { from._impl_.weights_ }, decltype(_impl_.biases_) {}, decltype(_impl_.low_) {}, decltype(_impl_.high_) {} };

    _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
    _impl_.biases_.InitDefault();
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.biases_.Set("", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
    if (from._internal_has_biases()) {
        _this->_impl_.biases_.Set(from._internal_biases(), _this->GetArenaForAllocation());
    }
    ::memcpy(&_impl_.low_, &from._impl_.low_,
        static_cast<size_t>(reinterpret_cast<char*>(&_impl_.high_) - reinterpret_cast<char*>(&_impl_.low_)) + sizeof(_impl_.high_));
    // @@protoc_insertion_point(copy_constructor:assist_ranker.QuantizedNNLayer)
}

inline void QuantizedNNLayer::SharedCtor(::_pb::Arena* arena, bool is_message_owned)
{
    (void)arena;
    (void)is_message_owned;
    new (&_impl_) Impl_ { decltype(_impl_._has_bits_) {}, /*decltype(_impl_._cached_size_)*/ {}, decltype(_impl_.weights_) { arena },
        decltype(_impl_.biases_) {}, decltype(_impl_.low_) { 0 }, decltype(_impl_.high_) { 0 } };
    _impl_.biases_.InitDefault();
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.biases_.Set("", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

QuantizedNNLayer::~QuantizedNNLayer()
{
    // @@protoc_insertion_point(destructor:assist_ranker.QuantizedNNLayer)
    if (auto* arena = _internal_metadata_.DeleteReturnArena<std::string>()) {
        (void)arena;
        return;
    }
    SharedDtor();
}

inline void QuantizedNNLayer::SharedDtor()
{
    GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
    _impl_.weights_.~RepeatedPtrField();
    _impl_.biases_.Destroy();
}

void QuantizedNNLayer::SetCachedSize(int size) const
{
    _impl_._cached_size_.Set(size);
}

void QuantizedNNLayer::Clear()
{
    // @@protoc_insertion_point(message_clear_start:assist_ranker.QuantizedNNLayer)
    uint32_t cached_has_bits = 0;
    // Prevent compiler warnings about cached_has_bits being unused
    (void)cached_has_bits;

    _impl_.weights_.Clear();
    cached_has_bits = _impl_._has_bits_[0];
    if (cached_has_bits & 0x00000001u) {
        _impl_.biases_.ClearNonDefaultToEmpty();
    }
    if (cached_has_bits & 0x00000006u) {
        ::memset(&_impl_.low_, 0, static_cast<size_t>(reinterpret_cast<char*>(&_impl_.high_) - reinterpret_cast<char*>(&_impl_.low_)) + sizeof(_impl_.high_));
    }
    _impl_._has_bits_.Clear();
    _internal_metadata_.Clear<std::string>();
}

const char* QuantizedNNLayer::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx)
{
#define CHK_(x)                                                                                                                                                \
    if (PROTOBUF_PREDICT_FALSE(!(x)))                                                                                                                          \
    goto failure
    _Internal::HasBits has_bits {};
    while (!ctx->Done(&ptr)) {
        uint32_t tag;
        ptr = ::_pbi::ReadTag(ptr, &tag);
        switch (tag >> 3) {
        // repeated bytes weights = 1;
        case 1:
            if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
                ptr -= 1;
                do {
                    ptr += 1;
                    auto str = _internal_add_weights();
                    ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
                    CHK_(ptr);
                    if (!ctx->DataAvailable(ptr))
                        break;
                } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<10>(ptr));
            } else
                goto handle_unusual;
            continue;
        // optional bytes biases = 2;
        case 2:
            if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
                auto str = _internal_mutable_biases();
                ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
                CHK_(ptr);
            } else
                goto handle_unusual;
            continue;
        // optional float low = 3;
        case 3:
            if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
                _Internal::set_has_low(&has_bits);
                _impl_.low_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
                ptr += sizeof(float);
            } else
                goto handle_unusual;
            continue;
        // optional float high = 4;
        case 4:
            if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 37)) {
                _Internal::set_has_high(&has_bits);
                _impl_.high_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
                ptr += sizeof(float);
            } else
                goto handle_unusual;
            continue;
        default:
            goto handle_unusual;
        } // switch
    handle_unusual:
        if ((tag == 0) || ((tag & 7) == 4)) {
            CHK_(ptr);
            ctx->SetLastTag(tag);
            goto message_done;
        }
        ptr = UnknownFieldParse(tag, _internal_metadata_.mutable_unknown_fields<std::string>(), ptr, ctx);
        CHK_(ptr != nullptr);
    } // while
message_done:
    _impl_._has_bits_.Or(has_bits);
    return ptr;
failure:
    ptr = nullptr;
    goto message_done;
#undef CHK_
}

uint8_t* QuantizedNNLayer::_InternalSerialize(uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const
{
    // @@protoc_insertion_point(serialize_to_array_start:assist_ranker.QuantizedNNLayer)
    uint32_t cached_has_bits = 0;
    (void)cached_has_bits;

    // repeated bytes weights = 1;
    for (int i = 0, n = this->_internal_weights_size(); i < n; i++) {
        const auto& s = this->_internal_weights(i);
        target = stream->WriteBytes(1, s, target);
    }

    cached_has_bits = _impl_._has_bits_[0];
    // optional bytes biases = 2;
    if (cached_has_bits & 0x00000001u) {
        target = stream->WriteBytesMaybeAliased(2, this->_internal_biases(), target);
    }

    // optional float low = 3;
    if (cached_has_bits & 0x00000002u) {
        target = stream->EnsureSpace(target);
        target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_low(), target);
    }

    // optional float high = 4;
    if (cached_has_bits & 0x00000004u) {
        target = stream->EnsureSpace(target);
        target = ::_pbi::WireFormatLite::WriteFloatToArray(4, this->_internal_high(), target);
    }

    if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
        target = stream->WriteRaw(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).data(),
            static_cast<int>(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size()), target);
    }
    // @@protoc_insertion_point(serialize_to_array_end:assist_ranker.QuantizedNNLayer)
    return target;
}

size_t QuantizedNNLayer::ByteSizeLong() const
{
    // @@protoc_insertion_point(message_byte_size_start:assist_ranker.QuantizedNNLayer)
    size_t total_size = 0;

    uint32_t cached_has_bits = 0;
    // Prevent compiler warnings about cached_has_bits being unused
    (void)cached_has_bits;

    // repeated bytes weights = 1;
    total_size += 1 * ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(_impl_.weights_.size());
    for (int i = 0, n = _impl_.weights_.size(); i < n; i++) {
        total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(_impl_.weights_.Get(i));
    }

    cached_has_bits = _impl_._has_bits_[0];
    if (cached_has_bits & 0x00000007u) {
        // optional bytes biases = 2;
        if (cached_has_bits & 0x00000001u) {
            total_size += 1 + ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(this->_internal_biases());
        }

        // optional float low = 3;
        if (cached_has_bits & 0x00000002u) {
            total_size += 1 + 4;
        }

        // optional float high = 4;
        if (cached_has_bits & 0x00000004u) {
            total_size += 1 + 4;
        }
    }
    if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
        total_size += _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size();
    }
    int cached_size = ::_pbi::ToCachedSize(total_size);
    SetCachedSize(cached_size);
    return total_size;
}

void QuantizedNNLayer::CheckTypeAndMergeFrom(const ::PROTOBUF_NAMESPACE_ID::MessageLite& from)
{
    MergeFrom(*::_pbi::DownCast<const QuantizedNNLayer*>(&from));
}

void QuantizedNNLayer::MergeFrom(const QuantizedNNLayer& from)
{
    QuantizedNNLayer* const _this = this;
    // @@protoc_insertion_point(class_specific_merge_from_start:assist_ranker.QuantizedNNLayer)
    GOOGLE_DCHECK_NE(&from, _this);
    uint32_t cached_has_bits = 0;
    (void)cached_has_bits;

    _this->_impl_.weights_.MergeFrom(from._impl_.weights_);
    cached_has_bits = from._impl_._has_bits_[0];
    if (cached_has_bits & 0x00000007u) {
        if (cached_has_bits & 0x00000001u) {
            _this->_internal_set_biases(from._internal_biases());
        }
        if (cached_has_bits & 0x00000002u) {
            _this->_impl_.low_ = from._impl_.low_;
        }
        if (cached_has_bits & 0x00000004u) {
            _this->_impl_.high_ = from._impl_.high_;
        }
        _this->_impl_._has_bits_[0] |= cached_has_bits;
    }
    _this->_internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
}

void QuantizedNNLayer::CopyFrom(const QuantizedNNLayer& from)
{
    // @@protoc_insertion_point(class_specific_copy_from_start:assist_ranker.QuantizedNNLayer)
    if (&from == this)
        return;
    Clear();
    MergeFrom(from);
}

bool QuantizedNNLayer::IsInitialized() const
{
    return true;
}

void QuantizedNNLayer::InternalSwap(QuantizedNNLayer* other)
{
    using std::swap;
    auto* lhs_arena = GetArenaForAllocation();
    auto* rhs_arena = other->GetArenaForAllocation();
    _internal_metadata_.InternalSwap(&other->_internal_metadata_);
    swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
    _impl_.weights_.InternalSwap(&other->_impl_.weights_);
    ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(&_impl_.biases_, lhs_arena, &other->_impl_.biases_, rhs_arena);
    ::PROTOBUF_NAMESPACE_ID::internal::memswap<PROTOBUF_FIELD_OFFSET(QuantizedNNLayer, _impl_.high_) + sizeof(QuantizedNNLayer::_impl_.high_)
        - PROTOBUF_FIELD_OFFSET(QuantizedNNLayer, _impl_.low_)>(reinterpret_cast<char*>(&_impl_.low_), reinterpret_cast<char*>(&other->_impl_.low_));
}

std::string QuantizedNNLayer::GetTypeName() const
{
    return "assist_ranker.QuantizedNNLayer";
}

// ===================================================================

class QuantizedNNClassifierModel::_Internal {
public:
    using HasBits = decltype(std::declval<QuantizedNNClassifierModel>()._impl_._has_bits_);
    static const ::assist_ranker::QuantizedNNLayer& hidden_layer(const QuantizedNNClassifierModel* msg);
    static void set_has_hidden_layer(HasBits* has_bits)
    {
        (*has_bits)[0] |= 1u;
    }
    static const ::assist_ranker::QuantizedNNLayer& logits_layer(const QuantizedNNClassifierModel* msg);
    static void set_has_logits_layer(HasBits* has_bits)
    {
        (*has_bits)[0] |= 2u;
    }
};

const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::_Internal::hidden_layer(const QuantizedNNClassifierModel* msg)
{
    return *msg->_impl_.hidden_layer_;
}
const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::_Internal::logits_layer(const QuantizedNNClassifierModel* msg)
{
    return *msg->_impl_.logits_layer_;
}
QuantizedNNClassifierModel::QuantizedNNClassifierModel(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned)
    : ::PROTOBUF_NAMESPACE_ID::MessageLite(arena, is_message_owned)
{
    SharedCtor(arena, is_message_owned);
    // @@protoc_insertion_point(arena_constructor:assist_ranker.QuantizedNNClassifierModel)
}
QuantizedNNClassifierModel::QuantizedNNClassifierModel(const QuantizedNNClassifierModel& from)
    : ::PROTOBUF_NAMESPACE_ID::MessageLite()
{
    QuantizedNNClassifierModel* const _this = this;
    (void)_this;
    new (&_impl_) Impl_ { decltype(_impl_._has_bits_) { from._impl_._has_bits_ }, /*decltype(_impl_._cached_size_)*/ {},
        decltype(_impl_.hidden_layer_) { nullptr }, decltype(_impl_.logits_layer_) { nullptr } };

    _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
    if (from._internal_has_hidden_layer()) {
        _this->_impl_.hidden_layer_ = new ::assist_ranker::QuantizedNNLayer(*from._impl_.hidden_layer_);
    }
    if (from._internal_has_logits_layer()) {
        _this->_impl_.logits_layer_ = new ::assist_ranker::QuantizedNNLayer(*from._impl_.logits_layer_);
    }
    // @@protoc_insertion_point(copy_constructor:assist_ranker.QuantizedNNClassifierModel)
}

inline void QuantizedNNClassifierModel::SharedCtor(::_pb::Arena* arena, bool is_message_owned)
{
    (void)arena;
    (void)is_message_owned;
    new (&_impl_) Impl_ { decltype(_impl_._has_bits_) {}, /*decltype(_impl_._cached_size_)*/ {}, decltype(_impl_.hidden_layer_) { nullptr },
        decltype(_impl_.logits_layer_) { nullptr } };
}

QuantizedNNClassifierModel::~QuantizedNNClassifierModel()
{
    // @@protoc_insertion_point(destructor:assist_ranker.QuantizedNNClassifierModel)
    if (auto* arena = _internal_metadata_.DeleteReturnArena<std::string>()) {
        (void)arena;
        return;
    }
    SharedDtor();
}

inline void QuantizedNNClassifierModel::SharedDtor()
{
    GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
    if (this != internal_default_instance())
        delete _impl_.hidden_layer_;
    if (this != internal_default_instance())
        delete _impl_.logits_layer_;
}

void QuantizedNNClassifierModel::SetCachedSize(int size) const
{
    _impl_._cached_size_.Set(size);
}

void QuantizedNNClassifierModel::Clear()
{
    // @@protoc_insertion_point(message_clear_start:assist_ranker.QuantizedNNClassifierModel)
    uint32_t cached_has_bits = 0;
    // Prevent compiler warnings about cached_has_bits being unused
    (void)cached_has_bits;

    cached_has_bits = _impl_._has_bits_[0];
    if (cached_has_bits & 0x00000003u) {
        if (cached_has_bits & 0x00000001u) {
            GOOGLE_DCHECK(_impl_.hidden_layer_ != nullptr);
            _impl_.hidden_layer_->Clear();
        }
        if (cached_has_bits & 0x00000002u) {
            GOOGLE_DCHECK(_impl_.logits_layer_ != nullptr);
            _impl_.logits_layer_->Clear();
        }
    }
    _impl_._has_bits_.Clear();
    _internal_metadata_.Clear<std::string>();
}

const char* QuantizedNNClassifierModel::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx)
{
#define CHK_(x)                                                                                                                                                \
    if (PROTOBUF_PREDICT_FALSE(!(x)))                                                                                                                          \
    goto failure
    _Internal::HasBits has_bits {};
    while (!ctx->Done(&ptr)) {
        uint32_t tag;
        ptr = ::_pbi::ReadTag(ptr, &tag);
        switch (tag >> 3) {
        // optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
        case 1:
            if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
                ptr = ctx->ParseMessage(_internal_mutable_hidden_layer(), ptr);
                CHK_(ptr);
            } else
                goto handle_unusual;
            continue;
        // optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
        case 2:
            if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
                ptr = ctx->ParseMessage(_internal_mutable_logits_layer(), ptr);
                CHK_(ptr);
            } else
                goto handle_unusual;
            continue;
        default:
            goto handle_unusual;
        } // switch
    handle_unusual:
        if ((tag == 0) || ((tag & 7) == 4)) {
            CHK_(ptr);
            ctx->SetLastTag(tag);
            goto message_done;
        }
        ptr = UnknownFieldParse(tag, _internal_metadata_.mutable_unknown_fields<std::string>(), ptr, ctx);
        CHK_(ptr != nullptr);
    } // while
message_done:
    _impl_._has_bits_.Or(has_bits);
    return ptr;
failure:
    ptr = nullptr;
    goto message_done;
#undef CHK_
}

uint8_t* QuantizedNNClassifierModel::_InternalSerialize(uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const
{
    // @@protoc_insertion_point(serialize_to_array_start:assist_ranker.QuantizedNNClassifierModel)
    uint32_t cached_has_bits = 0;
    (void)cached_has_bits;

    cached_has_bits = _impl_._has_bits_[0];
    // optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
    if (cached_has_bits & 0x00000001u) {
        target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::InternalWriteMessage(
            1, _Internal::hidden_layer(this), _Internal::hidden_layer(this).GetCachedSize(), target, stream);
    }

    // optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
    if (cached_has_bits & 0x00000002u) {
        target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::InternalWriteMessage(
            2, _Internal::logits_layer(this), _Internal::logits_layer(this).GetCachedSize(), target, stream);
    }

    if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
        target = stream->WriteRaw(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).data(),
            static_cast<int>(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size()), target);
    }
    // @@protoc_insertion_point(serialize_to_array_end:assist_ranker.QuantizedNNClassifierModel)
    return target;
}

size_t QuantizedNNClassifierModel::ByteSizeLong() const
{
    // @@protoc_insertion_point(message_byte_size_start:assist_ranker.QuantizedNNClassifierModel)
    size_t total_size = 0;

    uint32_t cached_has_bits = 0;
    // Prevent compiler warnings about cached_has_bits being unused
    (void)cached_has_bits;

    cached_has_bits = _impl_._has_bits_[0];
    if (cached_has_bits & 0x00000003u) {
        // optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
        if (cached_has_bits & 0x00000001u) {
            total_size += 1 + ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(*_impl_.hidden_layer_);
        }

        // optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
        if (cached_has_bits & 0x00000002u) {
            total_size += 1 + ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(*_impl_.logits_layer_);
        }
    }
    if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
        total_size += _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size();
    }
    int cached_size = ::_pbi::ToCachedSize(total_size);
    SetCachedSize(cached_size);
    return total_size;
}

void QuantizedNNClassifierModel::CheckTypeAndMergeFrom(const ::PROTOBUF_NAMESPACE_ID::MessageLite& from)
{
    MergeFrom(*::_pbi::DownCast<const QuantizedNNClassifierModel*>(&from));
}

void QuantizedNNClassifierModel::MergeFrom(const QuantizedNNClassifierModel& from)
{
    QuantizedNNClassifierModel* const _this = this;
    // @@protoc_insertion_point(class_specific_merge_from_start:assist_ranker.QuantizedNNClassifierModel)
    GOOGLE_DCHECK_NE(&from, _this);
    uint32_t cached_has_bits = 0;
    (void)cached_has_bits;

    cached_has_bits = from._impl_._has_bits_[0];
    if (cached_has_bits & 0x00000003u) {
        if (cached_has_bits & 0x00000001u) {
            _this->_internal_mutable_hidden_layer()->::assist_ranker::QuantizedNNLayer::MergeFrom(from._internal_hidden_layer());
        }
        if (cached_has_bits & 0x00000002u) {
            _this->_internal_mutable_logits_layer()->::assist_ranker::QuantizedNNLayer::MergeFrom(from._internal_logits_layer());
        }
    }
    _this->_internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
}

void QuantizedNNClassifierModel::CopyFrom(const QuantizedNNClassifierModel& from)
{
    // @@protoc_insertion_point(class_specific_copy_from_start:assist_ranker.QuantizedNNClassifierModel)
    if (&from == this)
        return;
    Clear();
    MergeFrom(from);
}

bool QuantizedNNClassifierModel::IsInitialized() const
{
    return true;
}

void QuantizedNNClassifierModel::InternalSwap(QuantizedNNClassifierModel* other)
{
    using std::swap;
    _internal_metadata_.InternalSwap(&other->_internal_metadata_);
    swap(_impl_._has_bits_[0], other->_impl_._has_bits_[0]);
    ::PROTOBUF_NAMESPACE_ID::internal::memswap<PROTOBUF_FIELD_OFFSET(QuantizedNNClassifierModel, _impl_.logits_layer_)
        + sizeof(QuantizedNNClassifierModel::_impl_.logits_layer_) - PROTOBUF_FIELD_OFFSET(QuantizedNNClassifierModel, _impl_.hidden_layer_)>(
        reinterpret_cast<char*>(&_impl_.hidden_layer_), reinterpret_cast<char*>(&other->_impl_.hidden_layer_));
}

std::string QuantizedNNClassifierModel::GetTypeName() const
{
    return "assist_ranker.QuantizedNNClassifierModel";
}

// @@protoc_insertion_point(namespace_scope)
} // namespace assist_ranker
PROTOBUF_NAMESPACE_OPEN
template <> PROTOBUF_NOINLINE ::assist_ranker::QuantizedNNLayer* Arena::CreateMaybeMessage<::assist_ranker::QuantizedNNLayer>(Arena* arena)
{
    return Arena::CreateMessageInternal<::assist_ranker::QuantizedNNLayer>(arena);
}
template <> PROTOBUF_NOINLINE ::assist_ranker::QuantizedNNClassifierModel* Arena::CreateMaybeMessage<::assist_ranker::QuantizedNNClassifierModel>(Arena* arena)
{
    return Arena::CreateMessageInternal<::assist_ranker::QuantizedNNClassifierModel>(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
